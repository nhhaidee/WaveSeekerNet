warning: refusing to reload ordenv; ORDENV_SETUP already set
CUDA_VISIBLE_DEVICES=0
Wed Jan 29 02:38:05 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:90:00.0 Off |                    0 |
| N/A   35C    P0             55W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Set Global Seed

FCGR Shape:
Train data shape: (44098, 2, 64, 64) (44098,)
Test High-quality Data Shape: (32257, 2, 64, 64) (32257,)
Test Low-quality Data Shape (Post 2020): (1463, 2, 64, 64) (1463,)
*************************Fold:  0 **********************************

Using: cuda:0!
Total Trainable Parameters:  1657121.0
Total Parameters:  1657121.0
Epoch 1: BCE Loss: 0.9824
KAN Loss: 0.0789, MH-SMoE (SA) Loss: 0.1235
Val Loss: 0.8617 Val BA-Score:  0.821016 Training Time:  26.136993 Inference Time:  0.876209
Epoch 2: BCE Loss: 0.4358
KAN Loss: 0.0561, MH-SMoE (SA) Loss: 0.0481
Val Loss: 0.5008 Val BA-Score:  0.947452 Training Time:  25.507391 Inference Time:  0.912802
Epoch 3: BCE Loss: 0.2794
KAN Loss: 0.0540, MH-SMoE (SA) Loss: 0.0407
Val Loss: 0.4423 Val BA-Score:  0.951412 Training Time:  25.605030 Inference Time:  0.910702
Epoch 4: BCE Loss: 0.1990
KAN Loss: 0.0587, MH-SMoE (SA) Loss: 0.0375
Val Loss: 0.3723 Val BA-Score:  0.940689 Training Time:  25.619224 Inference Time:  0.910713
Epoch 5: BCE Loss: 0.1614
KAN Loss: 0.0654, MH-SMoE (SA) Loss: 0.0358
Val Loss: 0.3467 Val BA-Score:  0.952467 Training Time:  25.647356 Inference Time:  0.903757
Epoch 6: BCE Loss: 0.1534
KAN Loss: 0.0742, MH-SMoE (SA) Loss: 0.0352
Val Loss: 0.3150 Val BA-Score:  0.950062 Training Time:  25.592242 Inference Time:  0.901835
Epoch 7: BCE Loss: 0.1460
KAN Loss: 0.0831, MH-SMoE (SA) Loss: 0.0342
Val Loss: 0.2260 Val BA-Score:  0.953817 Training Time:  25.505878 Inference Time:  0.906215
Epoch 8: BCE Loss: 0.1491
KAN Loss: 0.0918, MH-SMoE (SA) Loss: 0.0335
Val Loss: 0.6101 Val BA-Score:  0.865015 Training Time:  25.608213 Inference Time:  0.914359
Epoch 9: BCE Loss: 0.1406
KAN Loss: 0.0983, MH-SMoE (SA) Loss: 0.0329
Val Loss: 0.3246 Val BA-Score:  0.965207 Training Time:  25.586122 Inference Time:  0.904926
Epoch 10: BCE Loss: 0.1425
KAN Loss: 0.1029, MH-SMoE (SA) Loss: 0.0320
Val Loss: 0.2412 Val BA-Score:  0.963137 Training Time:  25.870306 Inference Time:  0.910012
Epoch 11: BCE Loss: 0.1281
KAN Loss: 0.1050, MH-SMoE (SA) Loss: 0.0327
Val Loss: 0.2367 Val BA-Score:  0.962519 Training Time:  25.662051 Inference Time:  0.906960
Epoch 12: BCE Loss: 0.1454
KAN Loss: 0.1057, MH-SMoE (SA) Loss: 0.0319
Val Loss: 0.2149 Val BA-Score:  0.965065 Training Time:  25.591583 Inference Time:  0.903086
Epoch 13: BCE Loss: 0.1220
KAN Loss: 0.1050, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.4389 Val BA-Score:  0.835599 Training Time:  25.504190 Inference Time:  0.911380
Epoch 14: BCE Loss: 0.1253
KAN Loss: 0.1036, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.3104 Val BA-Score:  0.879558 Training Time:  25.595070 Inference Time:  0.901793
Epoch 15: BCE Loss: 0.1196
KAN Loss: 0.1014, MH-SMoE (SA) Loss: 0.0315
Val Loss: 0.1920 Val BA-Score:  0.960288 Training Time:  25.536543 Inference Time:  0.907152
Epoch 16: BCE Loss: 0.1165
KAN Loss: 0.0983, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.3121 Val BA-Score:  0.899289 Training Time:  25.604244 Inference Time:  0.902088
Epoch 17: BCE Loss: 0.1162
KAN Loss: 0.0959, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.5250 Val BA-Score:  0.827058 Training Time:  25.839205 Inference Time:  0.900871
Epoch 18: BCE Loss: 0.1134
KAN Loss: 0.0918, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.1907 Val BA-Score:  0.966167 Training Time:  25.615030 Inference Time:  0.911458
Epoch 19: BCE Loss: 0.1071
KAN Loss: 0.0875, MH-SMoE (SA) Loss: 0.0309
Val Loss: 0.2858 Val BA-Score:  0.963621 Training Time:  25.492576 Inference Time:  0.904293
Epoch 20: BCE Loss: 0.1014
KAN Loss: 0.0836, MH-SMoE (SA) Loss: 0.0309
Val Loss: 0.2432 Val BA-Score:  0.969749 Training Time:  25.547996 Inference Time:  0.902979
Epoch 21: BCE Loss: 0.1011
KAN Loss: 0.0788, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2760 Val BA-Score:  0.967753 Training Time:  25.508650 Inference Time:  0.905889
Epoch 22: BCE Loss: 0.0973
KAN Loss: 0.0747, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.3036 Val BA-Score:  0.967478 Training Time:  25.605826 Inference Time:  0.901002
Epoch 23: BCE Loss: 0.0956
KAN Loss: 0.0686, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.3038 Val BA-Score:  0.968035 Training Time:  25.557330 Inference Time:  0.902926
Epoch 24: BCE Loss: 0.0936
KAN Loss: 0.0633, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2393 Val BA-Score:  0.969406 Training Time:  25.541466 Inference Time:  0.905428
Epoch 25: BCE Loss: 0.0910
KAN Loss: 0.0576, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2922 Val BA-Score:  0.967619 Training Time:  25.504345 Inference Time:  0.904244
Epoch 26: BCE Loss: 0.0888
KAN Loss: 0.0522, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.3013 Val BA-Score:  0.961040 Training Time:  25.542919 Inference Time:  0.905900
Epoch 27: BCE Loss: 0.0882
KAN Loss: 0.0469, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2881 Val BA-Score:  0.961994 Training Time:  25.541116 Inference Time:  0.906256
Epoch 28: BCE Loss: 0.0884
KAN Loss: 0.0416, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2397 Val BA-Score:  0.972652 Training Time:  25.547074 Inference Time:  0.911276
Epoch 29: BCE Loss: 0.0854
KAN Loss: 0.0360, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2568 Val BA-Score:  0.969688 Training Time:  25.724812 Inference Time:  0.907953
Epoch 30: BCE Loss: 0.0822
KAN Loss: 0.0304, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2383 Val BA-Score:  0.968580 Training Time:  25.521620 Inference Time:  0.904183
Epoch 31: BCE Loss: 0.0831
KAN Loss: 0.0256, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2436 Val BA-Score:  0.971052 Training Time:  25.727697 Inference Time:  0.904852
Epoch 32: BCE Loss: 0.0826
KAN Loss: 0.0219, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2621 Val BA-Score:  0.962276 Training Time:  25.483535 Inference Time:  0.903747
Epoch 33: BCE Loss: 0.0803
KAN Loss: 0.0191, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2405 Val BA-Score:  0.972920 Training Time:  25.536813 Inference Time:  0.901460
Epoch 34: BCE Loss: 0.0803
KAN Loss: 0.0172, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2817 Val BA-Score:  0.964420 Training Time:  25.666917 Inference Time:  0.904428
Epoch 35: BCE Loss: 0.0844
KAN Loss: 0.0161, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2552 Val BA-Score:  0.969339 Training Time:  25.586359 Inference Time:  0.904144
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.978933776486548 0.982649344569349 0.986727051051926 0.978933776486548 0.9784453201309704
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     23726
           1       0.98      1.00      0.99      5353
           2       0.98      0.94      0.96      3178

    accuracy                           0.99     32257
   macro avg       0.99      0.98      0.98     32257
weighted avg       0.99      0.99      0.99     32257

Low Quality (Post 2020)
0.9089207332816938 0.7818432157926848 0.7410849346643468 0.9089207332816938 0.9037640312827737
              precision    recall  f1-score   support

           0       1.00      0.98      0.99      1291
           1       0.98      1.00      0.99       160
           2       0.24      0.75      0.37        12

    accuracy                           0.98      1463
   macro avg       0.74      0.91      0.78      1463
weighted avg       0.99      0.98      0.98      1463


High Quality Post 2020
F1-Score (Macro)

                      mean  std  sem  count
Model                                      
Baseline_no_gMLP  0.982649  NaN  NaN      1
Balanced Accuracy

                      mean  std  sem  count
Model                                      
Baseline_no_gMLP  0.978934  NaN  NaN      1
MCC

                      mean  std  sem  count
Model                                      
Baseline_no_gMLP  0.978445  NaN  NaN      1

Low Quality Post 2020
F1-Score (Macro)

                      mean  std  sem  count
Model                                      
Baseline_no_gMLP  0.781843  NaN  NaN      1
Balanced Accuracy

                      mean  std  sem  count
Model                                      
Baseline_no_gMLP  0.908921  NaN  NaN      1
MCC

                      mean  std  sem  count
Model                                      
Baseline_no_gMLP  0.903764  NaN  NaN      1
*************************Fold:  1 **********************************

Using: cuda:0!
Total Trainable Parameters:  1657121.0
Total Parameters:  1657121.0
Epoch 1: BCE Loss: 0.9040
KAN Loss: 0.0780, MH-SMoE (SA) Loss: 0.1461
Val Loss: 0.7360 Val BA-Score:  0.684998 Training Time:  25.521397 Inference Time:  0.908936
Epoch 2: BCE Loss: 0.4122
KAN Loss: 0.0548, MH-SMoE (SA) Loss: 0.0532
Val Loss: 0.4447 Val BA-Score:  0.931538 Training Time:  25.718726 Inference Time:  0.912975
Epoch 3: BCE Loss: 0.2434
KAN Loss: 0.0533, MH-SMoE (SA) Loss: 0.0426
Val Loss: 0.3531 Val BA-Score:  0.954268 Training Time:  26.319637 Inference Time:  0.914765
Epoch 4: BCE Loss: 0.1753
KAN Loss: 0.0575, MH-SMoE (SA) Loss: 0.0377
Val Loss: 0.2897 Val BA-Score:  0.964098 Training Time:  25.833103 Inference Time:  0.907244
Epoch 5: BCE Loss: 0.1619
KAN Loss: 0.0642, MH-SMoE (SA) Loss: 0.0359
Val Loss: 0.2698 Val BA-Score:  0.955794 Training Time:  25.793957 Inference Time:  0.907642
Epoch 6: BCE Loss: 0.1516
KAN Loss: 0.0729, MH-SMoE (SA) Loss: 0.0356
Val Loss: 0.1999 Val BA-Score:  0.964334 Training Time:  25.857006 Inference Time:  0.911238
Epoch 7: BCE Loss: 0.1469
KAN Loss: 0.0814, MH-SMoE (SA) Loss: 0.0343
Val Loss: 2.1945 Val BA-Score:  0.333333 Training Time:  25.859820 Inference Time:  0.907556
Epoch 8: BCE Loss: 0.1860
KAN Loss: 0.0892, MH-SMoE (SA) Loss: 0.0337
Val Loss: 0.2231 Val BA-Score:  0.966538 Training Time:  25.932839 Inference Time:  0.906056
Epoch 9: BCE Loss: 0.1371
KAN Loss: 0.0958, MH-SMoE (SA) Loss: 0.0331
Val Loss: 0.6012 Val BA-Score:  0.637577 Training Time:  25.946916 Inference Time:  0.911128
Epoch 10: BCE Loss: 0.1358
KAN Loss: 0.1005, MH-SMoE (SA) Loss: 0.0332
Val Loss: 0.2126 Val BA-Score:  0.961303 Training Time:  25.810512 Inference Time:  0.908628
Epoch 11: BCE Loss: 0.1366
KAN Loss: 0.1028, MH-SMoE (SA) Loss: 0.0327
Val Loss: 0.3127 Val BA-Score:  0.951043 Training Time:  25.884675 Inference Time:  0.904048
Epoch 12: BCE Loss: 0.1353
KAN Loss: 0.1035, MH-SMoE (SA) Loss: 0.0320
Val Loss: 0.7494 Val BA-Score:  0.662044 Training Time:  25.771125 Inference Time:  0.912430
Epoch 13: BCE Loss: 0.1312
KAN Loss: 0.1031, MH-SMoE (SA) Loss: 0.0322
Val Loss: 0.1791 Val BA-Score:  0.964334 Training Time:  25.768979 Inference Time:  0.910411
Epoch 14: BCE Loss: 0.1157
KAN Loss: 0.1018, MH-SMoE (SA) Loss: 0.0322
Val Loss: 0.2110 Val BA-Score:  0.966262 Training Time:  25.730747 Inference Time:  0.905942
Epoch 15: BCE Loss: 0.1158
KAN Loss: 0.1000, MH-SMoE (SA) Loss: 0.0317
Val Loss: 0.1974 Val BA-Score:  0.961102 Training Time:  25.840236 Inference Time:  0.918414
Epoch 16: BCE Loss: 0.1157
KAN Loss: 0.0977, MH-SMoE (SA) Loss: 0.0318
Val Loss: 0.3558 Val BA-Score:  0.953920 Training Time:  25.884011 Inference Time:  0.914147
Epoch 17: BCE Loss: 0.1102
KAN Loss: 0.0951, MH-SMoE (SA) Loss: 0.0315
Val Loss: 0.2837 Val BA-Score:  0.939063 Training Time:  25.845129 Inference Time:  0.913274
Epoch 18: BCE Loss: 0.1077
KAN Loss: 0.0919, MH-SMoE (SA) Loss: 0.0314
Val Loss: 0.2769 Val BA-Score:  0.964273 Training Time:  25.823485 Inference Time:  0.913800
Epoch 19: BCE Loss: 0.1019
KAN Loss: 0.0885, MH-SMoE (SA) Loss: 0.0314
Val Loss: 0.2205 Val BA-Score:  0.957655 Training Time:  25.747769 Inference Time:  0.912802
Epoch 20: BCE Loss: 0.1024
KAN Loss: 0.0834, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.2533 Val BA-Score:  0.967572 Training Time:  25.775741 Inference Time:  0.910256
Epoch 21: BCE Loss: 0.0995
KAN Loss: 0.0791, MH-SMoE (SA) Loss: 0.0309
Val Loss: 0.3029 Val BA-Score:  0.964341 Training Time:  25.885461 Inference Time:  0.906954
Epoch 22: BCE Loss: 0.0982
KAN Loss: 0.0739, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2775 Val BA-Score:  0.969575 Training Time:  25.779272 Inference Time:  0.907191
Epoch 23: BCE Loss: 0.0971
KAN Loss: 0.0684, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2618 Val BA-Score:  0.971295 Training Time:  25.774229 Inference Time:  0.911880
Epoch 24: BCE Loss: 0.0940
KAN Loss: 0.0630, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.3214 Val BA-Score:  0.967713 Training Time:  25.829789 Inference Time:  0.910368
Epoch 25: BCE Loss: 0.0913
KAN Loss: 0.0570, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2953 Val BA-Score:  0.970475 Training Time:  25.809300 Inference Time:  0.905865
Epoch 26: BCE Loss: 0.0907
KAN Loss: 0.0520, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2592 Val BA-Score:  0.969850 Training Time:  25.777800 Inference Time:  0.908549
Epoch 27: BCE Loss: 0.0854
KAN Loss: 0.0467, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.3122 Val BA-Score:  0.969165 Training Time:  25.786702 Inference Time:  0.916859
Epoch 28: BCE Loss: 0.0823
KAN Loss: 0.0413, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.3647 Val BA-Score:  0.965033 Training Time:  25.839901 Inference Time:  0.906036
Epoch 29: BCE Loss: 0.0841
KAN Loss: 0.0358, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.3813 Val BA-Score:  0.969575 Training Time:  25.736283 Inference Time:  0.904661
Epoch 30: BCE Loss: 0.0810
KAN Loss: 0.0304, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.3403 Val BA-Score:  0.964690 Training Time:  25.792028 Inference Time:  0.906434
Epoch 31: BCE Loss: 0.0838
KAN Loss: 0.0255, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.3396 Val BA-Score:  0.962211 Training Time:  25.639312 Inference Time:  0.905651
Epoch 32: BCE Loss: 0.0804
KAN Loss: 0.0219, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.3647 Val BA-Score:  0.951467 Training Time:  25.718575 Inference Time:  0.912193
Epoch 33: BCE Loss: 0.0813
KAN Loss: 0.0191, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.3515 Val BA-Score:  0.961109 Training Time:  25.799197 Inference Time:  0.905597
Epoch 34: BCE Loss: 0.0807
KAN Loss: 0.0172, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.3279 Val BA-Score:  0.966135 Training Time:  25.938854 Inference Time:  0.906366
Epoch 35: BCE Loss: 0.0838
KAN Loss: 0.0161, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.3795 Val BA-Score:  0.962144 Training Time:  25.847439 Inference Time:  0.905204
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.9713191171249437 0.9782088184885471 0.9859155920492565 0.9713191171249437 0.9732500389308467
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     23726
           1       0.98      1.00      0.99      5353
           2       0.98      0.92      0.95      3178

    accuracy                           0.99     32257
   macro avg       0.99      0.97      0.98     32257
weighted avg       0.99      0.99      0.99     32257

Low Quality (Post 2020)
0.9153756777691712 0.9225162621059994 0.9307462597494411 0.9153756777691712 0.9741127114171665
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      1291
           1       0.98      1.00      0.99       160
           2       0.82      0.75      0.78        12

    accuracy                           0.99      1463
   macro avg       0.93      0.92      0.92      1463
weighted avg       0.99      0.99      0.99      1463


High Quality Post 2020
F1-Score (Macro)

                      mean      std      sem  count
Model                                              
Baseline_no_gMLP  0.980429  0.00314  0.00222      2
Balanced Accuracy

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.975126  0.005384  0.003807      2
MCC

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.975848  0.003674  0.002598      2

Low Quality Post 2020
F1-Score (Macro)

                     mean       std       sem  count
Model                                               
Baseline_no_gMLP  0.85218  0.099471  0.070337      2
Balanced Accuracy

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.912148  0.004564  0.003227      2
MCC

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.938938  0.049744  0.035174      2
*************************Fold:  2 **********************************

Using: cuda:0!
Total Trainable Parameters:  1657121.0
Total Parameters:  1657121.0
Epoch 1: BCE Loss: 1.0291
KAN Loss: 0.0794, MH-SMoE (SA) Loss: 0.1320
Val Loss: 0.9297 Val BA-Score:  0.625417 Training Time:  25.662347 Inference Time:  0.909188
Epoch 2: BCE Loss: 0.5322
KAN Loss: 0.0558, MH-SMoE (SA) Loss: 0.0516
Val Loss: 0.5810 Val BA-Score:  0.801567 Training Time:  25.823244 Inference Time:  0.912785
Epoch 3: BCE Loss: 0.2805
KAN Loss: 0.0532, MH-SMoE (SA) Loss: 0.0416
Val Loss: 0.3461 Val BA-Score:  0.932300 Training Time:  25.721312 Inference Time:  0.913045
Epoch 4: BCE Loss: 0.1936
KAN Loss: 0.0572, MH-SMoE (SA) Loss: 0.0385
Val Loss: 0.3814 Val BA-Score:  0.957472 Training Time:  25.923973 Inference Time:  0.909305
Epoch 5: BCE Loss: 0.1639
KAN Loss: 0.0643, MH-SMoE (SA) Loss: 0.0356
Val Loss: 0.2986 Val BA-Score:  0.960510 Training Time:  25.850139 Inference Time:  0.911252
Epoch 6: BCE Loss: 0.1572
KAN Loss: 0.0724, MH-SMoE (SA) Loss: 0.0351
Val Loss: 0.6904 Val BA-Score:  0.659020 Training Time:  25.910109 Inference Time:  0.911365
Epoch 7: BCE Loss: 0.1501
KAN Loss: 0.0803, MH-SMoE (SA) Loss: 0.0339
Val Loss: 0.2043 Val BA-Score:  0.964320 Training Time:  25.976583 Inference Time:  0.910643
Epoch 8: BCE Loss: 0.1482
KAN Loss: 0.0890, MH-SMoE (SA) Loss: 0.0333
Val Loss: 0.1937 Val BA-Score:  0.958796 Training Time:  26.584409 Inference Time:  0.913944
Epoch 9: BCE Loss: 0.1445
KAN Loss: 0.0955, MH-SMoE (SA) Loss: 0.0328
Val Loss: 0.3232 Val BA-Score:  0.954799 Training Time:  25.893169 Inference Time:  0.906432
Epoch 10: BCE Loss: 0.1416
KAN Loss: 0.1002, MH-SMoE (SA) Loss: 0.0328
Val Loss: 0.2102 Val BA-Score:  0.961290 Training Time:  26.016845 Inference Time:  0.913484
Epoch 11: BCE Loss: 0.1348
KAN Loss: 0.1026, MH-SMoE (SA) Loss: 0.0326
Val Loss: 0.2252 Val BA-Score:  0.962533 Training Time:  25.935396 Inference Time:  0.916128
Epoch 12: BCE Loss: 0.1288
KAN Loss: 0.1034, MH-SMoE (SA) Loss: 0.0320
Val Loss: 0.3220 Val BA-Score:  0.962875 Training Time:  25.834202 Inference Time:  0.908490
Epoch 13: BCE Loss: 0.1247
KAN Loss: 0.1029, MH-SMoE (SA) Loss: 0.0320
Val Loss: 0.1552 Val BA-Score:  0.969695 Training Time:  25.889458 Inference Time:  0.907598
Epoch 14: BCE Loss: 0.1223
KAN Loss: 0.1017, MH-SMoE (SA) Loss: 0.0316
Val Loss: 0.2318 Val BA-Score:  0.968216 Training Time:  26.035497 Inference Time:  0.904106
Epoch 15: BCE Loss: 0.1179
KAN Loss: 0.1000, MH-SMoE (SA) Loss: 0.0314
Val Loss: 0.2673 Val BA-Score:  0.961908 Training Time:  25.948294 Inference Time:  0.914689
Epoch 16: BCE Loss: 0.1189
KAN Loss: 0.0975, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.3938 Val BA-Score:  0.969372 Training Time:  26.287755 Inference Time:  0.907996
Epoch 17: BCE Loss: 0.1123
KAN Loss: 0.0950, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.2571 Val BA-Score:  0.965133 Training Time:  25.869529 Inference Time:  0.909873
Epoch 18: BCE Loss: 0.1077
KAN Loss: 0.0915, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.2737 Val BA-Score:  0.963473 Training Time:  25.850776 Inference Time:  0.909589
Epoch 19: BCE Loss: 0.1052
KAN Loss: 0.0879, MH-SMoE (SA) Loss: 0.0309
Val Loss: 0.2509 Val BA-Score:  0.966913 Training Time:  25.917609 Inference Time:  0.904225
Epoch 20: BCE Loss: 0.1025
KAN Loss: 0.0842, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.3273 Val BA-Score:  0.971214 Training Time:  25.840186 Inference Time:  0.909978
Epoch 21: BCE Loss: 0.1002
KAN Loss: 0.0784, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.2530 Val BA-Score:  0.962788 Training Time:  25.767669 Inference Time:  0.914140
Epoch 22: BCE Loss: 0.0982
KAN Loss: 0.0738, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.3104 Val BA-Score:  0.958896 Training Time:  25.929038 Inference Time:  0.910658
Epoch 23: BCE Loss: 0.0961
KAN Loss: 0.0693, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.3077 Val BA-Score:  0.973330 Training Time:  25.897077 Inference Time:  0.910215
Epoch 24: BCE Loss: 0.0945
KAN Loss: 0.0631, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2900 Val BA-Score:  0.969978 Training Time:  25.798774 Inference Time:  0.909021
Epoch 25: BCE Loss: 0.0945
KAN Loss: 0.0582, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.3709 Val BA-Score:  0.963035 Training Time:  25.889551 Inference Time:  0.906416
Epoch 26: BCE Loss: 0.0914
KAN Loss: 0.0521, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2605 Val BA-Score:  0.968600 Training Time:  25.805340 Inference Time:  0.906214
Epoch 27: BCE Loss: 0.0891
KAN Loss: 0.0473, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.3258 Val BA-Score:  0.968035 Training Time:  26.851236 Inference Time:  0.907965
Epoch 28: BCE Loss: 0.0846
KAN Loss: 0.0415, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2997 Val BA-Score:  0.967202 Training Time:  25.860311 Inference Time:  0.909426
Epoch 29: BCE Loss: 0.0847
KAN Loss: 0.0359, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2862 Val BA-Score:  0.970656 Training Time:  25.783814 Inference Time:  0.911881
Epoch 30: BCE Loss: 0.0819
KAN Loss: 0.0304, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2836 Val BA-Score:  0.968929 Training Time:  25.964005 Inference Time:  0.905909
Epoch 31: BCE Loss: 0.0827
KAN Loss: 0.0256, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.3033 Val BA-Score:  0.969406 Training Time:  25.883732 Inference Time:  0.908667
Epoch 32: BCE Loss: 0.0824
KAN Loss: 0.0219, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2893 Val BA-Score:  0.966073 Training Time:  25.786395 Inference Time:  0.907410
Epoch 33: BCE Loss: 0.0799
KAN Loss: 0.0192, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2896 Val BA-Score:  0.968640 Training Time:  25.892482 Inference Time:  0.910883
Epoch 34: BCE Loss: 0.0800
KAN Loss: 0.0172, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.3189 Val BA-Score:  0.966906 Training Time:  25.826918 Inference Time:  0.905270
Epoch 35: BCE Loss: 0.0817
KAN Loss: 0.0162, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.3160 Val BA-Score:  0.966080 Training Time:  26.039079 Inference Time:  0.904236
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.9749906586153845 0.9802833445215854 0.9861324130537991 0.9749906586153845 0.9756255750079805
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     23726
           1       0.98      1.00      0.99      5353
           2       0.98      0.93      0.96      3178

    accuracy                           0.99     32257
   macro avg       0.99      0.97      0.98     32257
weighted avg       0.99      0.99      0.99     32257

Low Quality (Post 2020)
0.9091789310611929 0.7830008954147472 0.7431050952499616 0.9091789310611929 0.9063850602207884
              precision    recall  f1-score   support

           0       1.00      0.98      0.99      1291
           1       0.99      1.00      0.99       160
           2       0.24      0.75      0.37        12

    accuracy                           0.98      1463
   macro avg       0.74      0.91      0.78      1463
weighted avg       0.99      0.98      0.98      1463


High Quality Post 2020
F1-Score (Macro)

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.980381  0.002222  0.001283      3
Balanced Accuracy

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.975081  0.003808  0.002199      3
MCC

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.975774  0.002601  0.001502      3

Low Quality Post 2020
F1-Score (Macro)

                     mean       std       sem  count
Model                                               
Baseline_no_gMLP  0.82912  0.080885  0.046699      3
Balanced Accuracy

                      mean       std      sem  count
Model                                               
Baseline_no_gMLP  0.911158  0.003655  0.00211      3
MCC

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.928087  0.039881  0.023025      3
*************************Fold:  3 **********************************

Using: cuda:0!
Total Trainable Parameters:  1657121.0
Total Parameters:  1657121.0
Epoch 1: BCE Loss: 0.9958
KAN Loss: 0.0790, MH-SMoE (SA) Loss: 0.1695
Val Loss: 0.8562 Val BA-Score:  0.650208 Training Time:  25.816391 Inference Time:  0.906608
Epoch 2: BCE Loss: 0.4520
KAN Loss: 0.0551, MH-SMoE (SA) Loss: 0.0618
Val Loss: 0.5348 Val BA-Score:  0.925327 Training Time:  25.759472 Inference Time:  0.921006
Epoch 3: BCE Loss: 0.2631
KAN Loss: 0.0537, MH-SMoE (SA) Loss: 0.0419
Val Loss: 0.5021 Val BA-Score:  0.855243 Training Time:  25.980092 Inference Time:  0.913541
Epoch 4: BCE Loss: 0.1892
KAN Loss: 0.0579, MH-SMoE (SA) Loss: 0.0394
Val Loss: 0.3762 Val BA-Score:  0.957412 Training Time:  25.890554 Inference Time:  0.918438
Epoch 5: BCE Loss: 0.1690
KAN Loss: 0.0643, MH-SMoE (SA) Loss: 0.0365
Val Loss: 0.3815 Val BA-Score:  0.962250 Training Time:  25.818511 Inference Time:  0.920840
Epoch 6: BCE Loss: 0.1590
KAN Loss: 0.0732, MH-SMoE (SA) Loss: 0.0355
Val Loss: 0.2100 Val BA-Score:  0.966107 Training Time:  25.905491 Inference Time:  0.920591
Epoch 7: BCE Loss: 0.1421
KAN Loss: 0.0822, MH-SMoE (SA) Loss: 0.0343
Val Loss: 0.4661 Val BA-Score:  0.726451 Training Time:  25.902353 Inference Time:  0.914973
Epoch 8: BCE Loss: 0.1731
KAN Loss: 0.0905, MH-SMoE (SA) Loss: 0.0342
Val Loss: 0.3439 Val BA-Score:  0.922648 Training Time:  25.912546 Inference Time:  0.910497
Epoch 9: BCE Loss: 0.1457
KAN Loss: 0.0974, MH-SMoE (SA) Loss: 0.0329
Val Loss: 0.2583 Val BA-Score:  0.961913 Training Time:  25.946530 Inference Time:  0.912225
Epoch 10: BCE Loss: 0.1398
KAN Loss: 0.1024, MH-SMoE (SA) Loss: 0.0333
Val Loss: 0.1467 Val BA-Score:  0.968936 Training Time:  25.967522 Inference Time:  0.911019
Epoch 11: BCE Loss: 0.1379
KAN Loss: 0.1047, MH-SMoE (SA) Loss: 0.0326
Val Loss: 1.2067 Val BA-Score:  0.345208 Training Time:  26.034675 Inference Time:  0.918458
Epoch 12: BCE Loss: 0.1463
KAN Loss: 0.1057, MH-SMoE (SA) Loss: 0.0322
Val Loss: 0.2493 Val BA-Score:  0.949384 Training Time:  25.842374 Inference Time:  0.912719
Epoch 13: BCE Loss: 0.1248
KAN Loss: 0.1050, MH-SMoE (SA) Loss: 0.0316
Val Loss: 0.1745 Val BA-Score:  0.962324 Training Time:  25.988655 Inference Time:  0.912428
Epoch 14: BCE Loss: 0.1294
KAN Loss: 0.1037, MH-SMoE (SA) Loss: 0.0317
Val Loss: 0.3208 Val BA-Score:  0.959637 Training Time:  26.755263 Inference Time:  0.910677
Epoch 15: BCE Loss: 0.1247
KAN Loss: 0.1013, MH-SMoE (SA) Loss: 0.0318
Val Loss: 0.1911 Val BA-Score:  0.969830 Training Time:  25.908873 Inference Time:  0.899040
Epoch 16: BCE Loss: 0.1180
KAN Loss: 0.0983, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.1534 Val BA-Score:  0.970045 Training Time:  25.806307 Inference Time:  0.913498
Epoch 17: BCE Loss: 0.1154
KAN Loss: 0.0956, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.3868 Val BA-Score:  0.800616 Training Time:  26.026786 Inference Time:  0.910815
Epoch 18: BCE Loss: 0.1147
KAN Loss: 0.0923, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.1618 Val BA-Score:  0.965012 Training Time:  25.876174 Inference Time:  0.910282
Epoch 19: BCE Loss: 0.1092
KAN Loss: 0.0886, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.2080 Val BA-Score:  0.968318 Training Time:  26.031960 Inference Time:  0.914105
Epoch 20: BCE Loss: 0.1129
KAN Loss: 0.0851, MH-SMoE (SA) Loss: 0.0309
Val Loss: 0.2551 Val BA-Score:  0.964192 Training Time:  25.959882 Inference Time:  0.910834
Epoch 21: BCE Loss: 0.1052
KAN Loss: 0.0799, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2283 Val BA-Score:  0.964676 Training Time:  25.835316 Inference Time:  0.908478
Epoch 22: BCE Loss: 0.1021
KAN Loss: 0.0756, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2695 Val BA-Score:  0.963642 Training Time:  25.901580 Inference Time:  0.913647
Epoch 23: BCE Loss: 0.1010
KAN Loss: 0.0703, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.1882 Val BA-Score:  0.968883 Training Time:  25.855055 Inference Time:  0.905645
Epoch 24: BCE Loss: 0.0994
KAN Loss: 0.0648, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2305 Val BA-Score:  0.967975 Training Time:  25.812070 Inference Time:  0.909264
Epoch 25: BCE Loss: 0.0992
KAN Loss: 0.0594, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2363 Val BA-Score:  0.971839 Training Time:  25.859084 Inference Time:  0.908958
Epoch 26: BCE Loss: 0.0967
KAN Loss: 0.0525, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2967 Val BA-Score:  0.968116 Training Time:  25.807102 Inference Time:  0.909005
Epoch 27: BCE Loss: 0.0920
KAN Loss: 0.0473, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2856 Val BA-Score:  0.964750 Training Time:  25.926694 Inference Time:  0.906285
Epoch 28: BCE Loss: 0.0903
KAN Loss: 0.0423, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2339 Val BA-Score:  0.967781 Training Time:  25.837086 Inference Time:  0.908782
Epoch 29: BCE Loss: 0.0900
KAN Loss: 0.0369, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2628 Val BA-Score:  0.964542 Training Time:  25.808590 Inference Time:  0.908657
Epoch 30: BCE Loss: 0.0875
KAN Loss: 0.0316, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2570 Val BA-Score:  0.967088 Training Time:  25.792209 Inference Time:  0.906754
Epoch 31: BCE Loss: 0.0888
KAN Loss: 0.0265, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2791 Val BA-Score:  0.967364 Training Time:  25.760498 Inference Time:  0.907794
Epoch 32: BCE Loss: 0.0854
KAN Loss: 0.0226, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2091 Val BA-Score:  0.972047 Training Time:  25.783709 Inference Time:  0.913907
Epoch 33: BCE Loss: 0.0872
KAN Loss: 0.0196, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2190 Val BA-Score:  0.969501 Training Time:  27.132822 Inference Time:  0.912827
Epoch 34: BCE Loss: 0.0871
KAN Loss: 0.0176, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2057 Val BA-Score:  0.971913 Training Time:  25.894324 Inference Time:  0.908605
Epoch 35: BCE Loss: 0.0858
KAN Loss: 0.0165, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2282 Val BA-Score:  0.968809 Training Time:  25.865892 Inference Time:  0.905463
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.9733747246719896 0.9793072486744858 0.9858967321914983 0.9733747246719896 0.9745130668997944
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     23726
           1       0.98      1.00      0.99      5353
           2       0.98      0.93      0.95      3178

    accuracy                           0.99     32257
   macro avg       0.99      0.97      0.98     32257
weighted avg       0.99      0.99      0.99     32257

Low Quality (Post 2020)
0.9094371288406919 0.7856839102246328 0.74535776443989 0.9094371288406919 0.9089377976138363
              precision    recall  f1-score   support

           0       1.00      0.98      0.99      1291
           1       0.99      1.00      0.99       160
           2       0.25      0.75      0.38        12

    accuracy                           0.98      1463
   macro avg       0.75      0.91      0.79      1463
weighted avg       0.99      0.98      0.98      1463


High Quality Post 2020
F1-Score (Macro)

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.980112  0.001892  0.000946      4
Balanced Accuracy

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.974655  0.003224  0.001612      4
MCC

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.975459  0.002215  0.001108      4

Low Quality Post 2020
F1-Score (Macro)

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.818261  0.069522  0.034761      4
Balanced Accuracy

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.910728  0.003106  0.001553      4
MCC

                    mean       std      sem  count
Model                                             
Baseline_no_gMLP  0.9233  0.033941  0.01697      4
*************************Fold:  4 **********************************

Using: cuda:0!
Total Trainable Parameters:  1657121.0
Total Parameters:  1657121.0
Epoch 1: BCE Loss: 0.9851
KAN Loss: 0.0795, MH-SMoE (SA) Loss: 0.1382
Val Loss: 0.7611 Val BA-Score:  0.642917 Training Time:  25.848462 Inference Time:  0.907349
Epoch 2: BCE Loss: 0.4370
KAN Loss: 0.0551, MH-SMoE (SA) Loss: 0.0500
Val Loss: 0.4087 Val BA-Score:  0.953616 Training Time:  26.054703 Inference Time:  0.904922
Epoch 3: BCE Loss: 0.2219
KAN Loss: 0.0533, MH-SMoE (SA) Loss: 0.0401
Val Loss: 0.3022 Val BA-Score:  0.961309 Training Time:  26.924813 Inference Time:  0.910974
Epoch 4: BCE Loss: 0.1720
KAN Loss: 0.0579, MH-SMoE (SA) Loss: 0.0380
Val Loss: 0.2804 Val BA-Score:  0.953495 Training Time:  25.857663 Inference Time:  0.913256
Epoch 5: BCE Loss: 0.1560
KAN Loss: 0.0652, MH-SMoE (SA) Loss: 0.0364
Val Loss: 0.3065 Val BA-Score:  0.961095 Training Time:  26.128381 Inference Time:  0.917890
Epoch 6: BCE Loss: 0.1465
KAN Loss: 0.0733, MH-SMoE (SA) Loss: 0.0349
Val Loss: 0.2619 Val BA-Score:  0.932300 Training Time:  25.891321 Inference Time:  0.912415
Epoch 7: BCE Loss: 0.1381
KAN Loss: 0.0821, MH-SMoE (SA) Loss: 0.0343
Val Loss: 0.2082 Val BA-Score:  0.969285 Training Time:  25.900689 Inference Time:  0.917227
Epoch 8: BCE Loss: 0.1385
KAN Loss: 0.0897, MH-SMoE (SA) Loss: 0.0328
Val Loss: 0.2450 Val BA-Score:  0.955618 Training Time:  25.989174 Inference Time:  0.907506
Epoch 9: BCE Loss: 0.1469
KAN Loss: 0.0960, MH-SMoE (SA) Loss: 0.0334
Val Loss: 0.2858 Val BA-Score:  0.927016 Training Time:  25.936060 Inference Time:  0.914463
Epoch 10: BCE Loss: 0.1316
KAN Loss: 0.1007, MH-SMoE (SA) Loss: 0.0322
Val Loss: 0.2292 Val BA-Score:  0.964260 Training Time:  26.032461 Inference Time:  0.910451
Epoch 11: BCE Loss: 0.1282
KAN Loss: 0.1031, MH-SMoE (SA) Loss: 0.0326
Val Loss: 0.1645 Val BA-Score:  0.962338 Training Time:  26.699394 Inference Time:  0.908140
Epoch 12: BCE Loss: 0.1244
KAN Loss: 0.1038, MH-SMoE (SA) Loss: 0.0319
Val Loss: 0.1966 Val BA-Score:  0.965146 Training Time:  25.924710 Inference Time:  0.906957
Epoch 13: BCE Loss: 0.1246
KAN Loss: 0.1032, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.3707 Val BA-Score:  0.899301 Training Time:  25.898100 Inference Time:  0.904468
Epoch 14: BCE Loss: 0.1192
KAN Loss: 0.1021, MH-SMoE (SA) Loss: 0.0319
Val Loss: 0.3028 Val BA-Score:  0.961982 Training Time:  25.986803 Inference Time:  0.913855
Epoch 15: BCE Loss: 0.1166
KAN Loss: 0.1004, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.2140 Val BA-Score:  0.965778 Training Time:  25.896592 Inference Time:  0.916671
Epoch 16: BCE Loss: 0.1105
KAN Loss: 0.0979, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.2270 Val BA-Score:  0.960026 Training Time:  25.996649 Inference Time:  0.916323
Epoch 17: BCE Loss: 0.1108
KAN Loss: 0.0953, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.1671 Val BA-Score:  0.968116 Training Time:  25.856699 Inference Time:  0.910182
Epoch 18: BCE Loss: 0.1078
KAN Loss: 0.0919, MH-SMoE (SA) Loss: 0.0309
Val Loss: 0.1909 Val BA-Score:  0.966463 Training Time:  25.779865 Inference Time:  0.911907
Epoch 19: BCE Loss: 0.1026
KAN Loss: 0.0883, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.1987 Val BA-Score:  0.960704 Training Time:  25.949435 Inference Time:  0.910632
Epoch 20: BCE Loss: 0.1002
KAN Loss: 0.0845, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2315 Val BA-Score:  0.962466 Training Time:  25.908027 Inference Time:  0.907176
Epoch 21: BCE Loss: 0.0984
KAN Loss: 0.0800, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.2673 Val BA-Score:  0.958077 Training Time:  26.152308 Inference Time:  0.917589
Epoch 22: BCE Loss: 0.0956
KAN Loss: 0.0746, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2343 Val BA-Score:  0.968674 Training Time:  25.982348 Inference Time:  0.907059
Epoch 23: BCE Loss: 0.0968
KAN Loss: 0.0692, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.3197 Val BA-Score:  0.958459 Training Time:  25.881969 Inference Time:  0.911994
Epoch 24: BCE Loss: 0.0905
KAN Loss: 0.0635, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2410 Val BA-Score:  0.962908 Training Time:  25.976817 Inference Time:  0.911431
Epoch 25: BCE Loss: 0.0916
KAN Loss: 0.0571, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2226 Val BA-Score:  0.967686 Training Time:  25.848082 Inference Time:  0.907676
Epoch 26: BCE Loss: 0.0876
KAN Loss: 0.0518, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.1946 Val BA-Score:  0.963184 Training Time:  25.915718 Inference Time:  0.908679
Epoch 27: BCE Loss: 0.0845
KAN Loss: 0.0470, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2417 Val BA-Score:  0.971772 Training Time:  25.949973 Inference Time:  0.913969
Epoch 28: BCE Loss: 0.0843
KAN Loss: 0.0415, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2404 Val BA-Score:  0.961510 Training Time:  26.055553 Inference Time:  0.909634
Epoch 29: BCE Loss: 0.0824
KAN Loss: 0.0358, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2329 Val BA-Score:  0.964151 Training Time:  26.173413 Inference Time:  0.907775
Epoch 30: BCE Loss: 0.0808
KAN Loss: 0.0304, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2364 Val BA-Score:  0.964836 Training Time:  25.873131 Inference Time:  0.908071
Epoch 31: BCE Loss: 0.0854
KAN Loss: 0.0257, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2203 Val BA-Score:  0.968781 Training Time:  25.835233 Inference Time:  0.911052
Epoch 32: BCE Loss: 0.0791
KAN Loss: 0.0221, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2219 Val BA-Score:  0.963802 Training Time:  25.914882 Inference Time:  0.908721
Epoch 33: BCE Loss: 0.0797
KAN Loss: 0.0194, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2442 Val BA-Score:  0.962223 Training Time:  25.855311 Inference Time:  0.909682
Epoch 34: BCE Loss: 0.0776
KAN Loss: 0.0175, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2405 Val BA-Score:  0.961033 Training Time:  25.955864 Inference Time:  0.909055
Epoch 35: BCE Loss: 0.0782
KAN Loss: 0.0165, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2272 Val BA-Score:  0.961792 Training Time:  25.945144 Inference Time:  0.914294
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.9735845002121616 0.9794342780219437 0.9859280655027605 0.9735845002121616 0.9746614730954599
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     23726
           1       0.98      1.00      0.99      5353
           2       0.98      0.93      0.95      3178

    accuracy                           0.99     32257
   macro avg       0.99      0.97      0.98     32257
weighted avg       0.99      0.99      0.99     32257

Low Quality (Post 2020)
0.9140846888716757 0.8630422717379239 0.8286984915113433 0.9140846888716757 0.9587952418895275
              precision    recall  f1-score   support

           0       1.00      0.99      1.00      1291
           1       0.99      1.00      0.99       160
           2       0.50      0.75      0.60        12

    accuracy                           0.99      1463
   macro avg       0.83      0.91      0.86      1463
weighted avg       0.99      0.99      0.99      1463


High Quality Post 2020
F1-Score (Macro)

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.979977  0.001666  0.000745      5
Balanced Accuracy

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.974441  0.002833  0.001267      5
MCC

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.975299  0.001951  0.000873      5

Low Quality Post 2020
F1-Score (Macro)

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.827217  0.063451  0.028376      5
Balanced Accuracy

                      mean      std       sem  count
Model                                               
Baseline_no_gMLP  0.911399  0.00308  0.001377      5
MCC

                      mean       std      sem  count
Model                                               
Baseline_no_gMLP  0.930399  0.033406  0.01494      5
*************************Fold:  5 **********************************

Using: cuda:0!
Total Trainable Parameters:  1657121.0
Total Parameters:  1657121.0
Epoch 1: BCE Loss: 1.0322
KAN Loss: 0.0772, MH-SMoE (SA) Loss: 0.1337
Val Loss: 0.9617 Val BA-Score:  0.618440 Training Time:  25.669322 Inference Time:  0.909447
Epoch 2: BCE Loss: 0.4733
KAN Loss: 0.0538, MH-SMoE (SA) Loss: 0.0491
Val Loss: 0.3909 Val BA-Score:  0.947817 Training Time:  25.802117 Inference Time:  0.918187
Epoch 3: BCE Loss: 0.2297
KAN Loss: 0.0538, MH-SMoE (SA) Loss: 0.0415
Val Loss: 0.3826 Val BA-Score:  0.953079 Training Time:  25.788736 Inference Time:  0.917262
Epoch 4: BCE Loss: 0.1735
KAN Loss: 0.0579, MH-SMoE (SA) Loss: 0.0379
Val Loss: 0.5131 Val BA-Score:  0.865076 Training Time:  25.917292 Inference Time:  0.914688
Epoch 5: BCE Loss: 0.1503
KAN Loss: 0.0646, MH-SMoE (SA) Loss: 0.0361
Val Loss: 0.3218 Val BA-Score:  0.949452 Training Time:  25.917869 Inference Time:  0.917879
Epoch 6: BCE Loss: 0.1488
KAN Loss: 0.0729, MH-SMoE (SA) Loss: 0.0356
Val Loss: 0.3390 Val BA-Score:  0.942299 Training Time:  26.091916 Inference Time:  0.907658
Epoch 7: BCE Loss: 0.1469
KAN Loss: 0.0814, MH-SMoE (SA) Loss: 0.0345
Val Loss: 0.2240 Val BA-Score:  0.959287 Training Time:  25.915252 Inference Time:  0.917919
Epoch 8: BCE Loss: 0.1363
KAN Loss: 0.0892, MH-SMoE (SA) Loss: 0.0338
Val Loss: 0.4698 Val BA-Score:  0.782064 Training Time:  25.917263 Inference Time:  0.913299
Epoch 9: BCE Loss: 0.1417
KAN Loss: 0.0959, MH-SMoE (SA) Loss: 0.0329
Val Loss: 0.1756 Val BA-Score:  0.961934 Training Time:  25.971570 Inference Time:  0.908026
Epoch 10: BCE Loss: 0.1340
KAN Loss: 0.1005, MH-SMoE (SA) Loss: 0.0326
Val Loss: 0.3051 Val BA-Score:  0.935580 Training Time:  25.998519 Inference Time:  0.909865
Epoch 11: BCE Loss: 0.1343
KAN Loss: 0.1029, MH-SMoE (SA) Loss: 0.0324
Val Loss: 0.2382 Val BA-Score:  0.950155 Training Time:  25.882353 Inference Time:  0.916312
Epoch 12: BCE Loss: 0.1233
KAN Loss: 0.1037, MH-SMoE (SA) Loss: 0.0316
Val Loss: 0.1518 Val BA-Score:  0.959683 Training Time:  25.922432 Inference Time:  0.910416
Epoch 13: BCE Loss: 0.1201
KAN Loss: 0.1030, MH-SMoE (SA) Loss: 0.0318
Val Loss: 0.4365 Val BA-Score:  0.856083 Training Time:  25.956577 Inference Time:  0.909301
Epoch 14: BCE Loss: 0.1195
KAN Loss: 0.1018, MH-SMoE (SA) Loss: 0.0314
Val Loss: 0.1854 Val BA-Score:  0.956827 Training Time:  25.855832 Inference Time:  0.910625
Epoch 15: BCE Loss: 0.1150
KAN Loss: 0.0998, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.2454 Val BA-Score:  0.967054 Training Time:  25.895927 Inference Time:  0.920828
Epoch 16: BCE Loss: 0.1143
KAN Loss: 0.0976, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.1781 Val BA-Score:  0.956290 Training Time:  26.102166 Inference Time:  0.911153
Epoch 17: BCE Loss: 0.1088
KAN Loss: 0.0948, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.2554 Val BA-Score:  0.929106 Training Time:  25.927358 Inference Time:  0.917223
Epoch 18: BCE Loss: 0.1069
KAN Loss: 0.0916, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.2142 Val BA-Score:  0.952977 Training Time:  25.981396 Inference Time:  0.899774
Epoch 19: BCE Loss: 0.1060
KAN Loss: 0.0881, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.2131 Val BA-Score:  0.960771 Training Time:  25.972271 Inference Time:  0.913016
Epoch 20: BCE Loss: 0.1021
KAN Loss: 0.0837, MH-SMoE (SA) Loss: 0.0309
Val Loss: 0.1988 Val BA-Score:  0.956706 Training Time:  25.891776 Inference Time:  0.903559
Epoch 21: BCE Loss: 0.0989
KAN Loss: 0.0794, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.1787 Val BA-Score:  0.957056 Training Time:  25.988721 Inference Time:  0.916519
Epoch 22: BCE Loss: 0.0953
KAN Loss: 0.0745, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.1807 Val BA-Score:  0.959878 Training Time:  26.011256 Inference Time:  0.904088
Epoch 23: BCE Loss: 0.0952
KAN Loss: 0.0693, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.1781 Val BA-Score:  0.960362 Training Time:  25.873260 Inference Time:  0.911655
Epoch 24: BCE Loss: 0.0925
KAN Loss: 0.0639, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.1923 Val BA-Score:  0.965723 Training Time:  25.971987 Inference Time:  0.909981
Epoch 25: BCE Loss: 0.0901
KAN Loss: 0.0581, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.1945 Val BA-Score:  0.957707 Training Time:  25.888998 Inference Time:  0.905706
Epoch 26: BCE Loss: 0.0896
KAN Loss: 0.0517, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2124 Val BA-Score:  0.957667 Training Time:  25.891508 Inference Time:  0.909641
Epoch 27: BCE Loss: 0.0864
KAN Loss: 0.0463, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2336 Val BA-Score:  0.952130 Training Time:  27.547439 Inference Time:  0.911153
Epoch 28: BCE Loss: 0.0861
KAN Loss: 0.0410, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.1907 Val BA-Score:  0.961591 Training Time:  26.041679 Inference Time:  0.909967
Epoch 29: BCE Loss: 0.0884
KAN Loss: 0.0358, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.1868 Val BA-Score:  0.962767 Training Time:  25.950298 Inference Time:  0.919228
Epoch 30: BCE Loss: 0.0864
KAN Loss: 0.0306, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.1751 Val BA-Score:  0.965045 Training Time:  26.021515 Inference Time:  0.913155
Epoch 31: BCE Loss: 0.0825
KAN Loss: 0.0259, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2061 Val BA-Score:  0.964971 Training Time:  25.783453 Inference Time:  0.909471
Epoch 32: BCE Loss: 0.0821
KAN Loss: 0.0222, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.1919 Val BA-Score:  0.966711 Training Time:  25.796793 Inference Time:  0.907724
Epoch 33: BCE Loss: 0.0827
KAN Loss: 0.0194, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.1983 Val BA-Score:  0.962142 Training Time:  25.895511 Inference Time:  0.910141
Epoch 34: BCE Loss: 0.0824
KAN Loss: 0.0176, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.1836 Val BA-Score:  0.963056 Training Time:  25.971867 Inference Time:  0.907370
Epoch 35: BCE Loss: 0.0824
KAN Loss: 0.0165, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2041 Val BA-Score:  0.966154 Training Time:  25.781475 Inference Time:  0.908945
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.9771506843950859 0.981582796102396 0.9864607209423267 0.9771506843950859 0.977184144887409
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     23726
           1       0.98      1.00      0.99      5353
           2       0.98      0.94      0.96      3178

    accuracy                           0.99     32257
   macro avg       0.99      0.98      0.98     32257
weighted avg       0.99      0.99      0.99     32257

Low Quality (Post 2020)
0.9117609088561839 0.8157133823037713 0.7731392652027572 0.9117609088561839 0.932896479033164
              precision    recall  f1-score   support

           0       1.00      0.99      0.99      1291
           1       0.99      1.00      0.99       160
           2       0.33      0.75      0.46        12

    accuracy                           0.98      1463
   macro avg       0.77      0.91      0.82      1463
weighted avg       0.99      0.98      0.99      1463


High Quality Post 2020
F1-Score (Macro)

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.980244  0.001628  0.000665      6
Balanced Accuracy

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.974892  0.002765  0.001129      6
MCC

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.975613  0.001907  0.000779      6

Low Quality Post 2020
F1-Score (Macro)

                    mean       std       sem  count
Model                                              
Baseline_no_gMLP  0.8253  0.056947  0.023248      6
Balanced Accuracy

                     mean       std       sem  count
Model                                               
Baseline_no_gMLP  0.91146  0.002759  0.001126      6
MCC

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.930815  0.029897  0.012205      6
*************************Fold:  6 **********************************

Using: cuda:0!
Total Trainable Parameters:  1657121.0
Total Parameters:  1657121.0
Epoch 1: BCE Loss: 0.9662
KAN Loss: 0.0782, MH-SMoE (SA) Loss: 0.1330
Val Loss: 0.8829 Val BA-Score:  0.651942 Training Time:  25.692791 Inference Time:  0.911615
Epoch 2: BCE Loss: 0.4725
KAN Loss: 0.0543, MH-SMoE (SA) Loss: 0.0522
Val Loss: 0.4963 Val BA-Score:  0.929602 Training Time:  25.823903 Inference Time:  0.907818
Epoch 3: BCE Loss: 0.2560
KAN Loss: 0.0530, MH-SMoE (SA) Loss: 0.0425
Val Loss: 0.5172 Val BA-Score:  0.932505 Training Time:  25.750934 Inference Time:  0.909239
Epoch 4: BCE Loss: 0.1811
KAN Loss: 0.0573, MH-SMoE (SA) Loss: 0.0378
Val Loss: 0.6653 Val BA-Score:  0.620193 Training Time:  25.864368 Inference Time:  0.910990
Epoch 5: BCE Loss: 0.1619
KAN Loss: 0.0649, MH-SMoE (SA) Loss: 0.0361
Val Loss: 0.3202 Val BA-Score:  0.956822 Training Time:  25.926019 Inference Time:  0.906956
Epoch 6: BCE Loss: 0.1604
KAN Loss: 0.0738, MH-SMoE (SA) Loss: 0.0354
Val Loss: 0.2381 Val BA-Score:  0.962607 Training Time:  25.934602 Inference Time:  0.914212
Epoch 7: BCE Loss: 0.1442
KAN Loss: 0.0828, MH-SMoE (SA) Loss: 0.0338
Val Loss: 0.2763 Val BA-Score:  0.944700 Training Time:  25.903884 Inference Time:  0.914962
Epoch 8: BCE Loss: 0.1414
KAN Loss: 0.0907, MH-SMoE (SA) Loss: 0.0333
Val Loss: 0.6841 Val BA-Score:  0.683812 Training Time:  25.893390 Inference Time:  0.911776
Epoch 9: BCE Loss: 0.1361
KAN Loss: 0.0964, MH-SMoE (SA) Loss: 0.0331
Val Loss: 0.2729 Val BA-Score:  0.931501 Training Time:  25.967638 Inference Time:  0.917861
Epoch 10: BCE Loss: 0.1403
KAN Loss: 0.1010, MH-SMoE (SA) Loss: 0.0323
Val Loss: 0.2168 Val BA-Score:  0.959852 Training Time:  25.991206 Inference Time:  0.915334
Epoch 11: BCE Loss: 0.1341
KAN Loss: 0.1032, MH-SMoE (SA) Loss: 0.0320
Val Loss: 0.2091 Val BA-Score:  0.960954 Training Time:  25.939335 Inference Time:  0.911118
Epoch 12: BCE Loss: 0.1270
KAN Loss: 0.1040, MH-SMoE (SA) Loss: 0.0320
Val Loss: 0.1695 Val BA-Score:  0.964535 Training Time:  25.925258 Inference Time:  0.910644
Epoch 13: BCE Loss: 0.1228
KAN Loss: 0.1034, MH-SMoE (SA) Loss: 0.0317
Val Loss: 0.2465 Val BA-Score:  0.966651 Training Time:  26.767712 Inference Time:  0.904893
Epoch 14: BCE Loss: 0.1189
KAN Loss: 0.1022, MH-SMoE (SA) Loss: 0.0314
Val Loss: 0.2912 Val BA-Score:  0.954893 Training Time:  27.342311 Inference Time:  0.911026
Epoch 15: BCE Loss: 0.1197
KAN Loss: 0.1005, MH-SMoE (SA) Loss: 0.0315
Val Loss: 0.3480 Val BA-Score:  0.948462 Training Time:  26.658771 Inference Time:  0.906734
Epoch 16: BCE Loss: 0.1169
KAN Loss: 0.0982, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.4933 Val BA-Score:  0.932800 Training Time:  25.914073 Inference Time:  0.916277
Epoch 17: BCE Loss: 0.1220
KAN Loss: 0.0962, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.2636 Val BA-Score:  0.953583 Training Time:  26.000099 Inference Time:  0.911575
Epoch 18: BCE Loss: 0.1061
KAN Loss: 0.0927, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.3455 Val BA-Score:  0.930308 Training Time:  25.917115 Inference Time:  0.907584
Epoch 19: BCE Loss: 0.1109
KAN Loss: 0.0894, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.4368 Val BA-Score:  0.710615 Training Time:  25.843191 Inference Time:  0.910640
Epoch 20: BCE Loss: 0.1027
KAN Loss: 0.0850, MH-SMoE (SA) Loss: 0.0309
Val Loss: 0.2077 Val BA-Score:  0.963709 Training Time:  25.867754 Inference Time:  0.913723
Epoch 21: BCE Loss: 0.0992
KAN Loss: 0.0802, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.3104 Val BA-Score:  0.956271 Training Time:  25.887435 Inference Time:  0.917176
Epoch 22: BCE Loss: 0.0992
KAN Loss: 0.0757, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2669 Val BA-Score:  0.962331 Training Time:  25.954830 Inference Time:  0.914148
Epoch 23: BCE Loss: 0.0990
KAN Loss: 0.0706, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.4319 Val BA-Score:  0.965362 Training Time:  25.991210 Inference Time:  0.908181
Epoch 24: BCE Loss: 0.0961
KAN Loss: 0.0648, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.3252 Val BA-Score:  0.960127 Training Time:  25.852200 Inference Time:  0.911067
Epoch 25: BCE Loss: 0.0929
KAN Loss: 0.0600, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.3037 Val BA-Score:  0.965637 Training Time:  26.046194 Inference Time:  0.914843
Epoch 26: BCE Loss: 0.0899
KAN Loss: 0.0534, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2396 Val BA-Score:  0.965294 Training Time:  25.798903 Inference Time:  0.907763
Epoch 27: BCE Loss: 0.0890
KAN Loss: 0.0480, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2878 Val BA-Score:  0.962607 Training Time:  25.863362 Inference Time:  0.907870
Epoch 28: BCE Loss: 0.0884
KAN Loss: 0.0429, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2834 Val BA-Score:  0.966880 Training Time:  25.949919 Inference Time:  0.910333
Epoch 29: BCE Loss: 0.0858
KAN Loss: 0.0379, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2692 Val BA-Score:  0.963709 Training Time:  25.820300 Inference Time:  0.912868
Epoch 30: BCE Loss: 0.0849
KAN Loss: 0.0325, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2833 Val BA-Score:  0.967156 Training Time:  25.895742 Inference Time:  0.910407
Epoch 31: BCE Loss: 0.0852
KAN Loss: 0.0279, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.3115 Val BA-Score:  0.961229 Training Time:  25.892374 Inference Time:  0.910860
Epoch 32: BCE Loss: 0.0820
KAN Loss: 0.0242, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2576 Val BA-Score:  0.967014 Training Time:  25.793105 Inference Time:  0.909986
Epoch 33: BCE Loss: 0.0832
KAN Loss: 0.0215, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2479 Val BA-Score:  0.966739 Training Time:  26.137343 Inference Time:  0.904430
Epoch 34: BCE Loss: 0.0837
KAN Loss: 0.0196, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2778 Val BA-Score:  0.963709 Training Time:  26.375620 Inference Time:  0.912736
Epoch 35: BCE Loss: 0.0831
KAN Loss: 0.0185, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2647 Val BA-Score:  0.965637 Training Time:  26.088170 Inference Time:  0.904377
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.9727308792291515 0.9790174245943116 0.9860224493823115 0.9727308792291515 0.9742156063284542
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     23726
           1       0.98      1.00      0.99      5353
           2       0.98      0.92      0.95      3178

    accuracy                           0.99     32257
   macro avg       0.99      0.97      0.98     32257
weighted avg       0.99      0.99      0.99     32257

Low Quality (Post 2020)
0.9140846888716757 0.8630422717379239 0.8286984915113433 0.9140846888716757 0.9587952418895275
              precision    recall  f1-score   support

           0       1.00      0.99      1.00      1291
           1       0.99      1.00      0.99       160
           2       0.50      0.75      0.60        12

    accuracy                           0.99      1463
   macro avg       0.83      0.91      0.86      1463
weighted avg       0.99      0.99      0.99      1463


High Quality Post 2020
F1-Score (Macro)

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.980069  0.001557  0.000588      7
Balanced Accuracy

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.974583  0.002653  0.001003      7
MCC

                      mean      std       sem  count
Model                                               
Baseline_no_gMLP  0.975414  0.00182  0.000688      7

Low Quality Post 2020
F1-Score (Macro)

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.830692  0.053907  0.020375      7
Balanced Accuracy

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.911835  0.002707  0.001023      7
MCC

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.934812  0.029269  0.011063      7
*************************Fold:  7 **********************************

Using: cuda:0!
Total Trainable Parameters:  1657121.0
Total Parameters:  1657121.0
Epoch 1: BCE Loss: 1.0370
KAN Loss: 0.0794, MH-SMoE (SA) Loss: 0.1447
Val Loss: 0.9760 Val BA-Score:  0.618580 Training Time:  25.959842 Inference Time:  0.908593
Epoch 2: BCE Loss: 0.4696
KAN Loss: 0.0549, MH-SMoE (SA) Loss: 0.0536
Val Loss: 0.5553 Val BA-Score:  0.943461 Training Time:  25.918761 Inference Time:  0.908226
Epoch 3: BCE Loss: 0.2398
KAN Loss: 0.0539, MH-SMoE (SA) Loss: 0.0414
Val Loss: 0.5186 Val BA-Score:  0.959563 Training Time:  25.853647 Inference Time:  0.922338
Epoch 4: BCE Loss: 0.1771
KAN Loss: 0.0583, MH-SMoE (SA) Loss: 0.0387
Val Loss: 0.4621 Val BA-Score:  0.941603 Training Time:  26.872338 Inference Time:  0.915856
Epoch 5: BCE Loss: 0.1625
KAN Loss: 0.0657, MH-SMoE (SA) Loss: 0.0364
Val Loss: 0.3591 Val BA-Score:  0.954558 Training Time:  25.890115 Inference Time:  0.915088
Epoch 6: BCE Loss: 0.1589
KAN Loss: 0.0737, MH-SMoE (SA) Loss: 0.0351
Val Loss: 0.9207 Val BA-Score:  0.588650 Training Time:  25.854256 Inference Time:  0.911482
Epoch 7: BCE Loss: 0.1634
KAN Loss: 0.0825, MH-SMoE (SA) Loss: 0.0345
Val Loss: 0.2688 Val BA-Score:  0.946985 Training Time:  26.022190 Inference Time:  0.913829
Epoch 8: BCE Loss: 0.1416
KAN Loss: 0.0900, MH-SMoE (SA) Loss: 0.0335
Val Loss: 0.3059 Val BA-Score:  0.942510 Training Time:  26.080438 Inference Time:  0.912450
Epoch 9: BCE Loss: 0.1620
KAN Loss: 0.0963, MH-SMoE (SA) Loss: 0.0328
Val Loss: 0.2378 Val BA-Score:  0.966195 Training Time:  26.175080 Inference Time:  0.911639
Epoch 10: BCE Loss: 0.1367
KAN Loss: 0.1006, MH-SMoE (SA) Loss: 0.0325
Val Loss: 0.3065 Val BA-Score:  0.935341 Training Time:  25.830188 Inference Time:  0.910500
Epoch 11: BCE Loss: 0.1272
KAN Loss: 0.1029, MH-SMoE (SA) Loss: 0.0321
Val Loss: 0.2881 Val BA-Score:  0.963514 Training Time:  25.980304 Inference Time:  0.916266
Epoch 12: BCE Loss: 0.1504
KAN Loss: 0.1035, MH-SMoE (SA) Loss: 0.0315
Val Loss: 0.2311 Val BA-Score:  0.966820 Training Time:  25.902953 Inference Time:  0.907217
Epoch 13: BCE Loss: 0.1233
KAN Loss: 0.1030, MH-SMoE (SA) Loss: 0.0314
Val Loss: 0.2409 Val BA-Score:  0.947194 Training Time:  25.876550 Inference Time:  0.907048
Epoch 14: BCE Loss: 0.1202
KAN Loss: 0.1019, MH-SMoE (SA) Loss: 0.0314
Val Loss: 0.4516 Val BA-Score:  0.928910 Training Time:  26.206829 Inference Time:  0.912537
Epoch 15: BCE Loss: 0.1177
KAN Loss: 0.1001, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.2489 Val BA-Score:  0.963239 Training Time:  25.965889 Inference Time:  0.908190
Epoch 16: BCE Loss: 0.1151
KAN Loss: 0.0977, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.2743 Val BA-Score:  0.967237 Training Time:  25.966078 Inference Time:  0.914788
Epoch 17: BCE Loss: 0.1106
KAN Loss: 0.0957, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.2134 Val BA-Score:  0.972517 Training Time:  25.983171 Inference Time:  0.909739
Epoch 18: BCE Loss: 0.1075
KAN Loss: 0.0926, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.2227 Val BA-Score:  0.971154 Training Time:  25.774494 Inference Time:  0.895818
Epoch 19: BCE Loss: 0.1078
KAN Loss: 0.0895, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.5148 Val BA-Score:  0.941510 Training Time:  25.843084 Inference Time:  0.912460
Epoch 20: BCE Loss: 0.1021
KAN Loss: 0.0843, MH-SMoE (SA) Loss: 0.0309
Val Loss: 0.3875 Val BA-Score:  0.953132 Training Time:  25.899795 Inference Time:  0.896844
Epoch 21: BCE Loss: 0.1002
KAN Loss: 0.0804, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.2913 Val BA-Score:  0.962021 Training Time:  25.985398 Inference Time:  0.909430
Epoch 22: BCE Loss: 0.1007
KAN Loss: 0.0753, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.4212 Val BA-Score:  0.949885 Training Time:  26.119064 Inference Time:  0.911945
Epoch 23: BCE Loss: 0.0956
KAN Loss: 0.0701, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.3039 Val BA-Score:  0.971779 Training Time:  25.916786 Inference Time:  0.910511
Epoch 24: BCE Loss: 0.0953
KAN Loss: 0.0635, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2701 Val BA-Score:  0.968392 Training Time:  25.829834 Inference Time:  0.906453
Epoch 25: BCE Loss: 0.0934
KAN Loss: 0.0576, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2811 Val BA-Score:  0.970119 Training Time:  25.824445 Inference Time:  0.911051
Epoch 26: BCE Loss: 0.0890
KAN Loss: 0.0514, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.3054 Val BA-Score:  0.965973 Training Time:  25.846159 Inference Time:  0.909530
Epoch 27: BCE Loss: 0.0875
KAN Loss: 0.0462, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2600 Val BA-Score:  0.968042 Training Time:  25.829994 Inference Time:  0.909831
Epoch 28: BCE Loss: 0.0881
KAN Loss: 0.0410, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.3137 Val BA-Score:  0.958614 Training Time:  25.790589 Inference Time:  0.910174
Epoch 29: BCE Loss: 0.0873
KAN Loss: 0.0358, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2921 Val BA-Score:  0.967961 Training Time:  25.956366 Inference Time:  0.905828
Epoch 30: BCE Loss: 0.0853
KAN Loss: 0.0306, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.3282 Val BA-Score:  0.966235 Training Time:  25.855010 Inference Time:  0.913536
Epoch 31: BCE Loss: 0.0823
KAN Loss: 0.0257, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.3105 Val BA-Score:  0.963607 Training Time:  25.841352 Inference Time:  0.910247
Epoch 32: BCE Loss: 0.0811
KAN Loss: 0.0220, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2834 Val BA-Score:  0.968788 Training Time:  25.763844 Inference Time:  0.907107
Epoch 33: BCE Loss: 0.0814
KAN Loss: 0.0193, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2927 Val BA-Score:  0.966584 Training Time:  26.035882 Inference Time:  0.909757
Epoch 34: BCE Loss: 0.0811
KAN Loss: 0.0174, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.3048 Val BA-Score:  0.965610 Training Time:  26.053668 Inference Time:  0.914358
Epoch 35: BCE Loss: 0.0803
KAN Loss: 0.0163, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2826 Val BA-Score:  0.967693 Training Time:  25.974968 Inference Time:  0.909459
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.9747663642528906 0.9802489211107778 0.9863193585614325 0.9747663642528906 0.9756246369697928
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     23726
           1       0.98      1.00      0.99      5353
           2       0.98      0.93      0.96      3178

    accuracy                           0.99     32257
   macro avg       0.99      0.97      0.98     32257
weighted avg       0.99      0.99      0.99     32257

Low Quality (Post 2020)
0.9153756777691712 0.9036915298513154 0.8928030727547634 0.9153756777691712 0.9741216043376423
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      1291
           1       0.99      1.00      0.99       160
           2       0.69      0.75      0.72        12

    accuracy                           0.99      1463
   macro avg       0.89      0.92      0.90      1463
weighted avg       0.99      0.99      0.99      1463


High Quality Post 2020
F1-Score (Macro)

                      mean       std      sem  count
Model                                               
Baseline_no_gMLP  0.980092  0.001443  0.00051      8
Balanced Accuracy

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.974606  0.002457  0.000869      8
MCC

                     mean       std       sem  count
Model                                               
Baseline_no_gMLP  0.97544  0.001686  0.000596      8

Low Quality Post 2020
F1-Score (Macro)

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.839817  0.056186  0.019865      8
Balanced Accuracy

                      mean       std      sem  count
Model                                               
Baseline_no_gMLP  0.912277  0.002801  0.00099      8
MCC

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.939726  0.030454  0.010767      8
*************************Fold:  8 **********************************

Using: cuda:0!
Total Trainable Parameters:  1657121.0
Total Parameters:  1657121.0
Epoch 1: BCE Loss: 0.9624
KAN Loss: 0.0778, MH-SMoE (SA) Loss: 0.1367
Val Loss: 0.7625 Val BA-Score:  0.665892 Training Time:  25.822424 Inference Time:  0.920826
Epoch 2: BCE Loss: 0.4101
KAN Loss: 0.0541, MH-SMoE (SA) Loss: 0.0527
Val Loss: 0.4592 Val BA-Score:  0.936096 Training Time:  25.891619 Inference Time:  0.918045
Epoch 3: BCE Loss: 0.2219
KAN Loss: 0.0531, MH-SMoE (SA) Loss: 0.0406
Val Loss: 0.4316 Val BA-Score:  0.934448 Training Time:  25.872391 Inference Time:  0.917063
Epoch 4: BCE Loss: 0.1689
KAN Loss: 0.0575, MH-SMoE (SA) Loss: 0.0376
Val Loss: 0.5073 Val BA-Score:  0.779412 Training Time:  26.159585 Inference Time:  0.911347
Epoch 5: BCE Loss: 0.1545
KAN Loss: 0.0644, MH-SMoE (SA) Loss: 0.0359
Val Loss: 0.3635 Val BA-Score:  0.904683 Training Time:  26.066650 Inference Time:  0.913296
Epoch 6: BCE Loss: 0.1521
KAN Loss: 0.0734, MH-SMoE (SA) Loss: 0.0348
Val Loss: 0.4500 Val BA-Score:  0.907201 Training Time:  26.060869 Inference Time:  0.917051
Epoch 7: BCE Loss: 0.1492
KAN Loss: 0.0830, MH-SMoE (SA) Loss: 0.0344
Val Loss: 1.0578 Val BA-Score:  0.660387 Training Time:  25.896716 Inference Time:  0.908556
Epoch 8: BCE Loss: 0.1592
KAN Loss: 0.0910, MH-SMoE (SA) Loss: 0.0334
Val Loss: 0.6277 Val BA-Score:  0.658958 Training Time:  26.030791 Inference Time:  0.916683
Epoch 9: BCE Loss: 0.1401
KAN Loss: 0.0979, MH-SMoE (SA) Loss: 0.0327
Val Loss: 0.2606 Val BA-Score:  0.946726 Training Time:  26.091380 Inference Time:  0.917496
Epoch 10: BCE Loss: 0.1339
KAN Loss: 0.1022, MH-SMoE (SA) Loss: 0.0326
Val Loss: 0.2898 Val BA-Score:  0.935771 Training Time:  25.866113 Inference Time:  0.921607
Epoch 11: BCE Loss: 0.1291
KAN Loss: 0.1045, MH-SMoE (SA) Loss: 0.0322
Val Loss: 0.9805 Val BA-Score:  0.659792 Training Time:  25.839275 Inference Time:  0.917553
Epoch 12: BCE Loss: 0.1280
KAN Loss: 0.1051, MH-SMoE (SA) Loss: 0.0322
Val Loss: 0.2783 Val BA-Score:  0.950794 Training Time:  25.907272 Inference Time:  0.914747
Epoch 13: BCE Loss: 0.1213
KAN Loss: 0.1047, MH-SMoE (SA) Loss: 0.0316
Val Loss: 0.1878 Val BA-Score:  0.958030 Training Time:  25.827239 Inference Time:  0.909524
Epoch 14: BCE Loss: 0.1183
KAN Loss: 0.1034, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.4893 Val BA-Score:  0.771147 Training Time:  25.961447 Inference Time:  0.910553
Epoch 15: BCE Loss: 0.1174
KAN Loss: 0.1010, MH-SMoE (SA) Loss: 0.0315
Val Loss: 0.2143 Val BA-Score:  0.962374 Training Time:  25.829683 Inference Time:  0.914163
Epoch 16: BCE Loss: 0.1137
KAN Loss: 0.0980, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.1972 Val BA-Score:  0.967055 Training Time:  26.064340 Inference Time:  0.918907
Epoch 17: BCE Loss: 0.1146
KAN Loss: 0.0953, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.6022 Val BA-Score:  0.692822 Training Time:  26.026920 Inference Time:  0.912485
Epoch 18: BCE Loss: 0.1073
KAN Loss: 0.0921, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.2146 Val BA-Score:  0.966301 Training Time:  25.847040 Inference Time:  0.914927
Epoch 19: BCE Loss: 0.1077
KAN Loss: 0.0884, MH-SMoE (SA) Loss: 0.0309
Val Loss: 0.3003 Val BA-Score:  0.949348 Training Time:  25.821008 Inference Time:  0.911293
Epoch 20: BCE Loss: 0.1063
KAN Loss: 0.0845, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.3343 Val BA-Score:  0.968041 Training Time:  27.025136 Inference Time:  0.911772
Epoch 21: BCE Loss: 0.1037
KAN Loss: 0.0798, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2800 Val BA-Score:  0.960358 Training Time:  25.986476 Inference Time:  0.907529
Epoch 22: BCE Loss: 0.0990
KAN Loss: 0.0750, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2629 Val BA-Score:  0.961669 Training Time:  25.957944 Inference Time:  0.912758
Epoch 23: BCE Loss: 0.0963
KAN Loss: 0.0702, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2833 Val BA-Score:  0.958140 Training Time:  25.906860 Inference Time:  0.912383
Epoch 24: BCE Loss: 0.0940
KAN Loss: 0.0642, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2989 Val BA-Score:  0.960499 Training Time:  25.925870 Inference Time:  0.913424
Epoch 25: BCE Loss: 0.0964
KAN Loss: 0.0591, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.3260 Val BA-Score:  0.965878 Training Time:  25.857425 Inference Time:  0.910238
Epoch 26: BCE Loss: 0.0900
KAN Loss: 0.0533, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.3134 Val BA-Score:  0.956816 Training Time:  25.970052 Inference Time:  0.905077
Epoch 27: BCE Loss: 0.0888
KAN Loss: 0.0478, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2968 Val BA-Score:  0.961167 Training Time:  25.905562 Inference Time:  0.910409
Epoch 28: BCE Loss: 0.0891
KAN Loss: 0.0429, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2958 Val BA-Score:  0.959868 Training Time:  25.923514 Inference Time:  0.910421
Epoch 29: BCE Loss: 0.0864
KAN Loss: 0.0372, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2590 Val BA-Score:  0.959365 Training Time:  25.820868 Inference Time:  0.911487
Epoch 30: BCE Loss: 0.0883
KAN Loss: 0.0318, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2930 Val BA-Score:  0.958422 Training Time:  25.945017 Inference Time:  0.907672
Epoch 31: BCE Loss: 0.0858
KAN Loss: 0.0268, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2940 Val BA-Score:  0.951737 Training Time:  26.005441 Inference Time:  0.908265
Epoch 32: BCE Loss: 0.0858
KAN Loss: 0.0230, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.3558 Val BA-Score:  0.938221 Training Time:  25.929379 Inference Time:  0.909331
Epoch 33: BCE Loss: 0.0841
KAN Loss: 0.0200, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2819 Val BA-Score:  0.965535 Training Time:  25.823254 Inference Time:  0.913597
Epoch 34: BCE Loss: 0.0829
KAN Loss: 0.0180, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2832 Val BA-Score:  0.957166 Training Time:  25.986443 Inference Time:  0.914277
Epoch 35: BCE Loss: 0.0826
KAN Loss: 0.0169, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2943 Val BA-Score:  0.963667 Training Time:  25.921238 Inference Time:  0.909243
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.9736125987819445 0.9795515301063783 0.9861478322081284 0.9736125987819445 0.9748085777250823
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     23726
           1       0.98      1.00      0.99      5353
           2       0.98      0.93      0.95      3178

    accuracy                           0.99     32257
   macro avg       0.99      0.97      0.98     32257
weighted avg       0.99      0.99      0.99     32257

Low Quality (Post 2020)
0.9158920733281694 0.9248200939658582 0.9347619171908578 0.9158920733281694 0.9804555977493298
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      1291
           1       0.99      1.00      0.99       160
           2       0.82      0.75      0.78        12

    accuracy                           1.00      1463
   macro avg       0.93      0.92      0.92      1463
weighted avg       1.00      1.00      1.00      1463


High Quality Post 2020
F1-Score (Macro)

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.980032  0.001362  0.000454      9
Balanced Accuracy

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.974496  0.002322  0.000774      9
MCC

                     mean       std      sem  count
Model                                              
Baseline_no_gMLP  0.97537  0.001591  0.00053      9

Low Quality Post 2020
F1-Score (Macro)

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.849262  0.059709  0.019903      9
Balanced Accuracy

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.912679  0.002884  0.000961      9
MCC

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.944252  0.031557  0.010519      9
*************************Fold:  9 **********************************

Using: cuda:0!
Total Trainable Parameters:  1657121.0
Total Parameters:  1657121.0
Epoch 1: BCE Loss: 0.9452
KAN Loss: 0.0775, MH-SMoE (SA) Loss: 0.1392
Val Loss: 0.8086 Val BA-Score:  0.613276 Training Time:  25.687545 Inference Time:  0.911160
Epoch 2: BCE Loss: 0.4302
KAN Loss: 0.0541, MH-SMoE (SA) Loss: 0.0555
Val Loss: 0.6137 Val BA-Score:  0.918287 Training Time:  25.830462 Inference Time:  0.910325
Epoch 3: BCE Loss: 0.2473
KAN Loss: 0.0533, MH-SMoE (SA) Loss: 0.0418
Val Loss: 0.3645 Val BA-Score:  0.958881 Training Time:  25.858193 Inference Time:  0.916192
Epoch 4: BCE Loss: 0.1858
KAN Loss: 0.0584, MH-SMoE (SA) Loss: 0.0386
Val Loss: 0.4762 Val BA-Score:  0.880050 Training Time:  25.938011 Inference Time:  0.914825
Epoch 5: BCE Loss: 0.1574
KAN Loss: 0.0647, MH-SMoE (SA) Loss: 0.0365
Val Loss: 0.3035 Val BA-Score:  0.951872 Training Time:  25.983247 Inference Time:  0.913172
Epoch 6: BCE Loss: 0.1475
KAN Loss: 0.0732, MH-SMoE (SA) Loss: 0.0344
Val Loss: 0.2690 Val BA-Score:  0.955659 Training Time:  25.994037 Inference Time:  0.911345
Epoch 7: BCE Loss: 0.1386
KAN Loss: 0.0824, MH-SMoE (SA) Loss: 0.0339
Val Loss: 0.5380 Val BA-Score:  0.807121 Training Time:  26.312041 Inference Time:  0.913595
Epoch 8: BCE Loss: 0.1385
KAN Loss: 0.0908, MH-SMoE (SA) Loss: 0.0334
Val Loss: 0.3580 Val BA-Score:  0.890332 Training Time:  25.994547 Inference Time:  0.911975
Epoch 9: BCE Loss: 0.1434
KAN Loss: 0.0973, MH-SMoE (SA) Loss: 0.0329
Val Loss: 0.2414 Val BA-Score:  0.960615 Training Time:  25.984619 Inference Time:  0.917556
Epoch 10: BCE Loss: 0.1306
KAN Loss: 0.1024, MH-SMoE (SA) Loss: 0.0324
Val Loss: 0.3895 Val BA-Score:  0.815105 Training Time:  26.008954 Inference Time:  0.919739
Epoch 11: BCE Loss: 0.1362
KAN Loss: 0.1044, MH-SMoE (SA) Loss: 0.0321
Val Loss: 0.6550 Val BA-Score:  0.621591 Training Time:  25.993304 Inference Time:  0.914191
Epoch 12: BCE Loss: 0.1252
KAN Loss: 0.1050, MH-SMoE (SA) Loss: 0.0316
Val Loss: 0.2626 Val BA-Score:  0.950475 Training Time:  25.980472 Inference Time:  0.913825
Epoch 13: BCE Loss: 0.1221
KAN Loss: 0.1041, MH-SMoE (SA) Loss: 0.0319
Val Loss: 0.5123 Val BA-Score:  0.835297 Training Time:  25.934945 Inference Time:  0.914273
Epoch 14: BCE Loss: 0.1229
KAN Loss: 0.1021, MH-SMoE (SA) Loss: 0.0316
Val Loss: 0.4148 Val BA-Score:  0.806287 Training Time:  25.904799 Inference Time:  0.913173
Epoch 15: BCE Loss: 0.1201
KAN Loss: 0.1001, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.2984 Val BA-Score:  0.956541 Training Time:  25.958217 Inference Time:  0.917999
Epoch 16: BCE Loss: 0.1130
KAN Loss: 0.0975, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.2781 Val BA-Score:  0.956253 Training Time:  26.007883 Inference Time:  0.910557
Epoch 17: BCE Loss: 0.1085
KAN Loss: 0.0951, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.2576 Val BA-Score:  0.956081 Training Time:  27.014632 Inference Time:  0.910697
Epoch 18: BCE Loss: 0.1083
KAN Loss: 0.0920, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2481 Val BA-Score:  0.961259 Training Time:  26.056826 Inference Time:  0.916033
Epoch 19: BCE Loss: 0.1064
KAN Loss: 0.0881, MH-SMoE (SA) Loss: 0.0309
Val Loss: 0.3136 Val BA-Score:  0.962699 Training Time:  26.028511 Inference Time:  0.914667
Epoch 20: BCE Loss: 0.1057
KAN Loss: 0.0840, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.4015 Val BA-Score:  0.959365 Training Time:  25.997755 Inference Time:  0.910306
Epoch 21: BCE Loss: 0.1035
KAN Loss: 0.0791, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.3253 Val BA-Score:  0.965670 Training Time:  25.871726 Inference Time:  0.916122
Epoch 22: BCE Loss: 0.0985
KAN Loss: 0.0744, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.4633 Val BA-Score:  0.867177 Training Time:  26.011708 Inference Time:  0.913469
Epoch 23: BCE Loss: 0.0966
KAN Loss: 0.0691, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.3510 Val BA-Score:  0.961369 Training Time:  25.920387 Inference Time:  0.890895
Epoch 24: BCE Loss: 0.0954
KAN Loss: 0.0633, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2518 Val BA-Score:  0.968274 Training Time:  25.915070 Inference Time:  0.912070
Epoch 25: BCE Loss: 0.0938
KAN Loss: 0.0570, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.3131 Val BA-Score:  0.964622 Training Time:  25.928114 Inference Time:  0.910908
Epoch 26: BCE Loss: 0.0920
KAN Loss: 0.0513, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.3144 Val BA-Score:  0.961651 Training Time:  25.868166 Inference Time:  0.913974
Epoch 27: BCE Loss: 0.0885
KAN Loss: 0.0461, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2926 Val BA-Score:  0.966068 Training Time:  25.947357 Inference Time:  0.914924
Epoch 28: BCE Loss: 0.0872
KAN Loss: 0.0415, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.3407 Val BA-Score:  0.968280 Training Time:  25.869131 Inference Time:  0.912609
Epoch 29: BCE Loss: 0.0858
KAN Loss: 0.0359, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.3338 Val BA-Score:  0.963642 Training Time:  25.930461 Inference Time:  0.912586
Epoch 30: BCE Loss: 0.0853
KAN Loss: 0.0303, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2880 Val BA-Score:  0.963366 Training Time:  25.963280 Inference Time:  0.908018
Epoch 31: BCE Loss: 0.0835
KAN Loss: 0.0256, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.3083 Val BA-Score:  0.960180 Training Time:  25.756273 Inference Time:  0.913256
Epoch 32: BCE Loss: 0.0852
KAN Loss: 0.0219, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.3203 Val BA-Score:  0.960542 Training Time:  25.857771 Inference Time:  0.910897
Epoch 33: BCE Loss: 0.0825
KAN Loss: 0.0192, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2950 Val BA-Score:  0.962061 Training Time:  25.934981 Inference Time:  0.911188
Epoch 34: BCE Loss: 0.0825
KAN Loss: 0.0173, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.3163 Val BA-Score:  0.967373 Training Time:  25.953420 Inference Time:  0.911385
Epoch 35: BCE Loss: 0.0818
KAN Loss: 0.0163, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.3176 Val BA-Score:  0.961638 Training Time:  25.955305 Inference Time:  0.906080
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.9734173420640945 0.9793326540200992 0.9858974337054134 0.9734173420640945 0.9745125344831332
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     23726
           1       0.98      1.00      0.99      5353
           2       0.98      0.93      0.95      3178

    accuracy                           0.99     32257
   macro avg       0.99      0.97      0.98     32257
weighted avg       0.99      0.99      0.99     32257

Low Quality (Post 2020)
0.9153756777691712 0.9036915298513154 0.8928030727547634 0.9153756777691712 0.9741216043376423
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      1291
           1       0.99      1.00      0.99       160
           2       0.69      0.75      0.72        12

    accuracy                           0.99      1463
   macro avg       0.89      0.92      0.90      1463
weighted avg       0.99      0.99      0.99      1463


High Quality Post 2020
F1-Score (Macro)

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.979962  0.001303  0.000412     10
Balanced Accuracy

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.974388  0.002216  0.000701     10
MCC

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.975284  0.001525  0.000482     10

Low Quality Post 2020
F1-Score (Macro)

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.854705  0.058867  0.018615     10
Balanced Accuracy

                      mean      std       sem  count
Model                                               
Baseline_no_gMLP  0.912949  0.00285  0.000901     10
MCC

                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.947239  0.031216  0.009871     10
