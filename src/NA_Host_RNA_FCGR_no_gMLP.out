warning: refusing to reload ordenv; ORDENV_SETUP already set
CUDA_VISIBLE_DEVICES=0
Tue Jan 28 18:49:31 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:BD:00.0 Off |                    0 |
| N/A   42C    P0             56W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Set Global Seed

FCGR Shape:
Train data shape: (45812, 64, 64) (45812,)
Test High-quality Data Shape: (44760, 64, 64) (44760,)
Test Low-quality Data Shape (Post 2020): (2221, 64, 64) (2221,)
*************************Fold:  0 **********************************

Using: cuda:0!
Total Trainable Parameters:  1033761.0
Total Parameters:  1033761.0
Epoch 1: BCE Loss: 0.9820
KAN Loss: 0.0775, MH-SMoE (SA) Loss: 0.1255
Val Loss: 0.7997 Val BA-Score:  0.871059 Training Time:  18.813958 Inference Time:  0.557645
Epoch 2: BCE Loss: 0.4921
KAN Loss: 0.0536, MH-SMoE (SA) Loss: 0.0500
Val Loss: 0.5331 Val BA-Score:  0.939686 Training Time:  18.742443 Inference Time:  0.575864
Epoch 3: BCE Loss: 0.3030
KAN Loss: 0.0534, MH-SMoE (SA) Loss: 0.0408
Val Loss: 0.4247 Val BA-Score:  0.955662 Training Time:  18.765824 Inference Time:  0.581118
Epoch 4: BCE Loss: 0.2238
KAN Loss: 0.0580, MH-SMoE (SA) Loss: 0.0385
Val Loss: 0.4181 Val BA-Score:  0.918927 Training Time:  18.934251 Inference Time:  0.578639
Epoch 5: BCE Loss: 0.1887
KAN Loss: 0.0649, MH-SMoE (SA) Loss: 0.0362
Val Loss: 0.3274 Val BA-Score:  0.955443 Training Time:  18.787459 Inference Time:  0.575278
Epoch 6: BCE Loss: 0.1775
KAN Loss: 0.0738, MH-SMoE (SA) Loss: 0.0346
Val Loss: 0.3019 Val BA-Score:  0.959642 Training Time:  18.843066 Inference Time:  0.577077
Epoch 7: BCE Loss: 0.1633
KAN Loss: 0.0822, MH-SMoE (SA) Loss: 0.0340
Val Loss: 0.2270 Val BA-Score:  0.962448 Training Time:  18.668479 Inference Time:  0.582665
Epoch 8: BCE Loss: 0.1607
KAN Loss: 0.0895, MH-SMoE (SA) Loss: 0.0337
Val Loss: 0.3538 Val BA-Score:  0.956802 Training Time:  18.762997 Inference Time:  0.582946
Epoch 9: BCE Loss: 0.1556
KAN Loss: 0.0959, MH-SMoE (SA) Loss: 0.0332
Val Loss: 0.3113 Val BA-Score:  0.923565 Training Time:  18.635501 Inference Time:  0.577953
Epoch 10: BCE Loss: 0.1567
KAN Loss: 0.1005, MH-SMoE (SA) Loss: 0.0324
Val Loss: 0.2171 Val BA-Score:  0.961823 Training Time:  18.697659 Inference Time:  0.575550
Epoch 11: BCE Loss: 0.1446
KAN Loss: 0.1029, MH-SMoE (SA) Loss: 0.0322
Val Loss: 1.2472 Val BA-Score:  0.491425 Training Time:  18.580198 Inference Time:  0.561988
Epoch 12: BCE Loss: 0.1462
KAN Loss: 0.1034, MH-SMoE (SA) Loss: 0.0323
Val Loss: 0.2396 Val BA-Score:  0.961746 Training Time:  18.677819 Inference Time:  0.578515
Epoch 13: BCE Loss: 0.1347
KAN Loss: 0.1027, MH-SMoE (SA) Loss: 0.0321
Val Loss: 0.2311 Val BA-Score:  0.966023 Training Time:  18.624104 Inference Time:  0.578674
Epoch 14: BCE Loss: 0.1325
KAN Loss: 0.1017, MH-SMoE (SA) Loss: 0.0316
Val Loss: 0.1827 Val BA-Score:  0.967514 Training Time:  18.729646 Inference Time:  0.581065
Epoch 15: BCE Loss: 0.1330
KAN Loss: 0.0998, MH-SMoE (SA) Loss: 0.0319
Val Loss: 0.2354 Val BA-Score:  0.951789 Training Time:  19.455570 Inference Time:  0.579401
Epoch 16: BCE Loss: 0.1287
KAN Loss: 0.0974, MH-SMoE (SA) Loss: 0.0316
Val Loss: 0.4351 Val BA-Score:  0.812897 Training Time:  18.797334 Inference Time:  0.584550
Epoch 17: BCE Loss: 0.1233
KAN Loss: 0.0946, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.1756 Val BA-Score:  0.967130 Training Time:  18.883997 Inference Time:  0.579057
Epoch 18: BCE Loss: 0.1197
KAN Loss: 0.0913, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.2289 Val BA-Score:  0.966988 Training Time:  18.611195 Inference Time:  0.578701
Epoch 19: BCE Loss: 0.1178
KAN Loss: 0.0882, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.2601 Val BA-Score:  0.966560 Training Time:  18.837954 Inference Time:  0.578495
Epoch 20: BCE Loss: 0.1164
KAN Loss: 0.0838, MH-SMoE (SA) Loss: 0.0309
Val Loss: 0.2438 Val BA-Score:  0.962602 Training Time:  18.886707 Inference Time:  0.572623
Epoch 21: BCE Loss: 0.1130
KAN Loss: 0.0800, MH-SMoE (SA) Loss: 0.0309
Val Loss: 0.2503 Val BA-Score:  0.967941 Training Time:  18.885189 Inference Time:  0.578217
Epoch 22: BCE Loss: 0.1108
KAN Loss: 0.0745, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2240 Val BA-Score:  0.966023 Training Time:  18.774727 Inference Time:  0.585829
Epoch 23: BCE Loss: 0.1095
KAN Loss: 0.0683, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.2301 Val BA-Score:  0.963150 Training Time:  18.892180 Inference Time:  0.578439
Epoch 24: BCE Loss: 0.1082
KAN Loss: 0.0632, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2546 Val BA-Score:  0.967316 Training Time:  18.912791 Inference Time:  0.579392
Epoch 25: BCE Loss: 0.1051
KAN Loss: 0.0571, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2605 Val BA-Score:  0.968457 Training Time:  18.898917 Inference Time:  0.580021
Epoch 26: BCE Loss: 0.1035
KAN Loss: 0.0523, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2249 Val BA-Score:  0.967941 Training Time:  18.789573 Inference Time:  0.583522
Epoch 27: BCE Loss: 0.1028
KAN Loss: 0.0465, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2808 Val BA-Score:  0.968884 Training Time:  18.894790 Inference Time:  0.581721
Epoch 28: BCE Loss: 0.1002
KAN Loss: 0.0412, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2354 Val BA-Score:  0.968819 Training Time:  18.864164 Inference Time:  0.577242
Epoch 29: BCE Loss: 0.0999
KAN Loss: 0.0357, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2234 Val BA-Score:  0.969016 Training Time:  18.788475 Inference Time:  0.580354
Epoch 30: BCE Loss: 0.0982
KAN Loss: 0.0303, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2349 Val BA-Score:  0.967876 Training Time:  18.826341 Inference Time:  0.574950
Epoch 31: BCE Loss: 0.0964
KAN Loss: 0.0256, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2446 Val BA-Score:  0.967788 Training Time:  19.067582 Inference Time:  0.578092
Epoch 32: BCE Loss: 0.0975
KAN Loss: 0.0219, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2408 Val BA-Score:  0.968314 Training Time:  18.868618 Inference Time:  0.579821
Epoch 33: BCE Loss: 0.0997
KAN Loss: 0.0192, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2375 Val BA-Score:  0.969487 Training Time:  18.874441 Inference Time:  0.580072
Epoch 34: BCE Loss: 0.0957
KAN Loss: 0.0173, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2366 Val BA-Score:  0.968281 Training Time:  18.827309 Inference Time:  0.579906
Epoch 35: BCE Loss: 0.0948
KAN Loss: 0.0163, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2484 Val BA-Score:  0.966472 Training Time:  18.986014 Inference Time:  0.580367
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.9743148159683642 0.9799719825213851 0.9861355221045892 0.9743148159683642 0.9774207949647997
              precision    recall  f1-score   support

           0       0.99      1.00      1.00     34537
           1       0.98      1.00      0.99      6756
           2       0.98      0.93      0.95      3467

    accuracy                           0.99     44760
   macro avg       0.99      0.97      0.98     44760
weighted avg       0.99      0.99      0.99     44760

Low Quality (Post 2020)
0.932051282051282 0.7571328949990038 0.7196625613557907 0.932051282051282 0.8286808175469894
              precision    recall  f1-score   support

           0       1.00      0.95      0.97      1960
           1       0.97      1.00      0.98       235
           2       0.19      0.85      0.31        26

    accuracy                           0.95      2221
   macro avg       0.72      0.93      0.76      2221
weighted avg       0.99      0.95      0.97      2221


High Quality Post 2020
                      mean  std  sem  count
Model                                      
Baseline_no_gMLP  0.979972  NaN  NaN      1
                      mean  std  sem  count
Model                                      
Baseline_no_gMLP  0.974315  NaN  NaN      1
                      mean  std  sem  count
Model                                      
Baseline_no_gMLP  0.977421  NaN  NaN      1

Low Quality Post 2020
                      mean  std  sem  count
Model                                      
Baseline_no_gMLP  0.757133  NaN  NaN      1
                      mean  std  sem  count
Model                                      
Baseline_no_gMLP  0.932051  NaN  NaN      1
                      mean  std  sem  count
Model                                      
Baseline_no_gMLP  0.828681  NaN  NaN      1
*************************Fold:  1 **********************************

Using: cuda:0!
Total Trainable Parameters:  1033761.0
Total Parameters:  1033761.0
Epoch 1: BCE Loss: 1.0213
KAN Loss: 0.0788, MH-SMoE (SA) Loss: 0.1410
Val Loss: 0.9233 Val BA-Score:  0.819777 Training Time:  19.117610 Inference Time:  0.579415
Epoch 2: BCE Loss: 0.4870
KAN Loss: 0.0545, MH-SMoE (SA) Loss: 0.0573
Val Loss: 0.5275 Val BA-Score:  0.914110 Training Time:  19.005532 Inference Time:  0.582365
Epoch 3: BCE Loss: 0.3270
KAN Loss: 0.0528, MH-SMoE (SA) Loss: 0.0441
Val Loss: 0.4479 Val BA-Score:  0.915517 Training Time:  18.866568 Inference Time:  0.584060
Epoch 4: BCE Loss: 0.2397
KAN Loss: 0.0571, MH-SMoE (SA) Loss: 0.0395
Val Loss: 0.3348 Val BA-Score:  0.945850 Training Time:  18.890678 Inference Time:  0.588193
Epoch 5: BCE Loss: 0.1961
KAN Loss: 0.0644, MH-SMoE (SA) Loss: 0.0365
Val Loss: 0.3533 Val BA-Score:  0.960343 Training Time:  18.810316 Inference Time:  0.581793
Epoch 6: BCE Loss: 0.1728
KAN Loss: 0.0726, MH-SMoE (SA) Loss: 0.0355
Val Loss: 0.2508 Val BA-Score:  0.955158 Training Time:  18.876185 Inference Time:  0.583676
Epoch 7: BCE Loss: 0.1629
KAN Loss: 0.0812, MH-SMoE (SA) Loss: 0.0341
Val Loss: 0.2387 Val BA-Score:  0.957362 Training Time:  18.926115 Inference Time:  0.581463
Epoch 8: BCE Loss: 0.1657
KAN Loss: 0.0894, MH-SMoE (SA) Loss: 0.0337
Val Loss: 0.4265 Val BA-Score:  0.826086 Training Time:  18.995349 Inference Time:  0.582424
Epoch 9: BCE Loss: 0.1566
KAN Loss: 0.0963, MH-SMoE (SA) Loss: 0.0330
Val Loss: 0.2343 Val BA-Score:  0.964630 Training Time:  18.904285 Inference Time:  0.583118
Epoch 10: BCE Loss: 0.1533
KAN Loss: 0.1010, MH-SMoE (SA) Loss: 0.0328
Val Loss: 0.2286 Val BA-Score:  0.965595 Training Time:  19.004574 Inference Time:  0.587780
Epoch 11: BCE Loss: 0.1451
KAN Loss: 0.1033, MH-SMoE (SA) Loss: 0.0321
Val Loss: 0.2107 Val BA-Score:  0.963194 Training Time:  18.948349 Inference Time:  0.581270
Epoch 12: BCE Loss: 0.1456
KAN Loss: 0.1039, MH-SMoE (SA) Loss: 0.0318
Val Loss: 0.3810 Val BA-Score:  0.848483 Training Time:  18.944480 Inference Time:  0.583227
Epoch 13: BCE Loss: 0.1474
KAN Loss: 0.1035, MH-SMoE (SA) Loss: 0.0318
Val Loss: 0.1967 Val BA-Score:  0.962043 Training Time:  18.971627 Inference Time:  0.584318
Epoch 14: BCE Loss: 0.1310
KAN Loss: 0.1025, MH-SMoE (SA) Loss: 0.0316
Val Loss: 0.2135 Val BA-Score:  0.960399 Training Time:  19.007025 Inference Time:  0.578331
Epoch 15: BCE Loss: 0.1289
KAN Loss: 0.1007, MH-SMoE (SA) Loss: 0.0316
Val Loss: 0.2130 Val BA-Score:  0.961846 Training Time:  19.503170 Inference Time:  0.582376
Epoch 16: BCE Loss: 0.1245
KAN Loss: 0.0984, MH-SMoE (SA) Loss: 0.0315
Val Loss: 0.2429 Val BA-Score:  0.950959 Training Time:  18.969148 Inference Time:  0.583678
Epoch 17: BCE Loss: 0.1245
KAN Loss: 0.0957, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.1977 Val BA-Score:  0.963775 Training Time:  18.954604 Inference Time:  0.581994
Epoch 18: BCE Loss: 0.1200
KAN Loss: 0.0923, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.2038 Val BA-Score:  0.965223 Training Time:  18.986660 Inference Time:  0.581323
Epoch 19: BCE Loss: 0.1175
KAN Loss: 0.0891, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.2547 Val BA-Score:  0.953196 Training Time:  18.992476 Inference Time:  0.583162
Epoch 20: BCE Loss: 0.1177
KAN Loss: 0.0848, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.2200 Val BA-Score:  0.963808 Training Time:  18.878673 Inference Time:  0.581259
Epoch 21: BCE Loss: 0.1139
KAN Loss: 0.0806, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.2090 Val BA-Score:  0.963293 Training Time:  18.996403 Inference Time:  0.583341
Epoch 22: BCE Loss: 0.1132
KAN Loss: 0.0758, MH-SMoE (SA) Loss: 0.0309
Val Loss: 0.2465 Val BA-Score:  0.965738 Training Time:  18.956584 Inference Time:  0.582991
Epoch 23: BCE Loss: 0.1118
KAN Loss: 0.0705, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2985 Val BA-Score:  0.962953 Training Time:  19.025135 Inference Time:  0.583177
Epoch 24: BCE Loss: 0.1084
KAN Loss: 0.0646, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.2679 Val BA-Score:  0.963260 Training Time:  18.946575 Inference Time:  0.580464
Epoch 25: BCE Loss: 0.1060
KAN Loss: 0.0591, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.2543 Val BA-Score:  0.965223 Training Time:  19.054560 Inference Time:  0.580480
Epoch 26: BCE Loss: 0.1016
KAN Loss: 0.0531, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2425 Val BA-Score:  0.967634 Training Time:  18.968772 Inference Time:  0.581149
Epoch 27: BCE Loss: 0.1049
KAN Loss: 0.0477, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2460 Val BA-Score:  0.968358 Training Time:  19.112071 Inference Time:  0.585284
Epoch 28: BCE Loss: 0.0993
KAN Loss: 0.0428, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2207 Val BA-Score:  0.968391 Training Time:  18.911447 Inference Time:  0.584651
Epoch 29: BCE Loss: 0.1022
KAN Loss: 0.0371, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2475 Val BA-Score:  0.964499 Training Time:  19.039763 Inference Time:  0.585107
Epoch 30: BCE Loss: 0.0978
KAN Loss: 0.0316, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2449 Val BA-Score:  0.966187 Training Time:  18.903477 Inference Time:  0.584168
Epoch 31: BCE Loss: 0.0982
KAN Loss: 0.0266, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2360 Val BA-Score:  0.964981 Training Time:  18.998479 Inference Time:  0.583920
Epoch 32: BCE Loss: 0.0994
KAN Loss: 0.0225, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2304 Val BA-Score:  0.965946 Training Time:  18.936510 Inference Time:  0.582584
Epoch 33: BCE Loss: 0.0989
KAN Loss: 0.0195, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2329 Val BA-Score:  0.966670 Training Time:  18.999362 Inference Time:  0.584166
Epoch 34: BCE Loss: 0.0989
KAN Loss: 0.0175, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2255 Val BA-Score:  0.966428 Training Time:  18.899633 Inference Time:  0.579879
Epoch 35: BCE Loss: 0.0976
KAN Loss: 0.0164, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2276 Val BA-Score:  0.966187 Training Time:  19.292479 Inference Time:  0.577246
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.9698025376151654 0.9777918698319835 0.9866769877963556 0.9698025376151654 0.9750141468495943
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     34537
           1       0.98      1.00      0.99      6756
           2       0.98      0.91      0.95      3467

    accuracy                           0.99     44760
   macro avg       0.99      0.97      0.98     44760
weighted avg       0.99      0.99      0.99     44760

Low Quality (Post 2020)
0.8815541601255887 0.8784583011789299 0.8759418062067194 0.8815541601255887 0.9433774782473104
              precision    recall  f1-score   support

           0       1.00      0.99      0.99      1960
           1       0.95      1.00      0.98       235
           2       0.68      0.65      0.67        26

    accuracy                           0.99      2221
   macro avg       0.88      0.88      0.88      2221
weighted avg       0.99      0.99      0.99      2221


High Quality Post 2020
                      mean       std      sem  count
Model                                               
Baseline_no_gMLP  0.978882  0.001542  0.00109      2
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.972059  0.003191  0.002256      2
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.976217  0.001702  0.001203      2

Low Quality Post 2020
                      mean      std       sem  count
Model                                               
Baseline_no_gMLP  0.817796  0.08579  0.060663      2
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.906803  0.035707  0.025249      2
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.886029  0.081103  0.057348      2
*************************Fold:  2 **********************************

Using: cuda:0!
Total Trainable Parameters:  1033761.0
Total Parameters:  1033761.0
Epoch 1: BCE Loss: 0.9562
KAN Loss: 0.0773, MH-SMoE (SA) Loss: 0.1156
Val Loss: 0.8448 Val BA-Score:  0.638958 Training Time:  18.885532 Inference Time:  0.589397
Epoch 2: BCE Loss: 0.5567
KAN Loss: 0.0541, MH-SMoE (SA) Loss: 0.0499
Val Loss: 0.5676 Val BA-Score:  0.928608 Training Time:  18.760321 Inference Time:  0.580241
Epoch 3: BCE Loss: 0.3381
KAN Loss: 0.0526, MH-SMoE (SA) Loss: 0.0424
Val Loss: 0.3742 Val BA-Score:  0.948391 Training Time:  18.709391 Inference Time:  0.583622
Epoch 4: BCE Loss: 0.2213
KAN Loss: 0.0572, MH-SMoE (SA) Loss: 0.0380
Val Loss: 0.4246 Val BA-Score:  0.941319 Training Time:  18.889059 Inference Time:  0.584966
Epoch 5: BCE Loss: 0.1801
KAN Loss: 0.0634, MH-SMoE (SA) Loss: 0.0367
Val Loss: 0.3806 Val BA-Score:  0.956965 Training Time:  18.854135 Inference Time:  0.579736
Epoch 6: BCE Loss: 0.1675
KAN Loss: 0.0720, MH-SMoE (SA) Loss: 0.0349
Val Loss: 0.2566 Val BA-Score:  0.957794 Training Time:  18.820944 Inference Time:  0.582577
Epoch 7: BCE Loss: 0.1642
KAN Loss: 0.0817, MH-SMoE (SA) Loss: 0.0344
Val Loss: 0.3711 Val BA-Score:  0.859571 Training Time:  18.829492 Inference Time:  0.584099
Epoch 8: BCE Loss: 0.1550
KAN Loss: 0.0901, MH-SMoE (SA) Loss: 0.0333
Val Loss: 0.2988 Val BA-Score:  0.944668 Training Time:  18.880035 Inference Time:  0.582939
Epoch 9: BCE Loss: 0.1575
KAN Loss: 0.0966, MH-SMoE (SA) Loss: 0.0327
Val Loss: 0.2136 Val BA-Score:  0.959872 Training Time:  18.808689 Inference Time:  0.583236
Epoch 10: BCE Loss: 0.1470
KAN Loss: 0.1009, MH-SMoE (SA) Loss: 0.0326
Val Loss: 0.2449 Val BA-Score:  0.958225 Training Time:  18.939306 Inference Time:  0.582595
Epoch 11: BCE Loss: 0.1468
KAN Loss: 0.1032, MH-SMoE (SA) Loss: 0.0320
Val Loss: 0.1985 Val BA-Score:  0.964227 Training Time:  18.810093 Inference Time:  0.589165
Epoch 12: BCE Loss: 0.1377
KAN Loss: 0.1037, MH-SMoE (SA) Loss: 0.0320
Val Loss: 0.4109 Val BA-Score:  0.920072 Training Time:  18.903771 Inference Time:  0.582800
Epoch 13: BCE Loss: 0.1358
KAN Loss: 0.1029, MH-SMoE (SA) Loss: 0.0320
Val Loss: 0.1971 Val BA-Score:  0.961122 Training Time:  18.798035 Inference Time:  0.581872
Epoch 14: BCE Loss: 0.1313
KAN Loss: 0.1021, MH-SMoE (SA) Loss: 0.0317
Val Loss: 0.3012 Val BA-Score:  0.898384 Training Time:  18.882668 Inference Time:  0.585109
Epoch 15: BCE Loss: 0.1295
KAN Loss: 0.1003, MH-SMoE (SA) Loss: 0.0316
Val Loss: 0.2374 Val BA-Score:  0.962999 Training Time:  18.841179 Inference Time:  0.582914
Epoch 16: BCE Loss: 0.1256
KAN Loss: 0.0979, MH-SMoE (SA) Loss: 0.0317
Val Loss: 0.2234 Val BA-Score:  0.961638 Training Time:  18.907333 Inference Time:  0.581209
Epoch 17: BCE Loss: 0.1205
KAN Loss: 0.0955, MH-SMoE (SA) Loss: 0.0314
Val Loss: 0.2568 Val BA-Score:  0.967156 Training Time:  18.924871 Inference Time:  0.577675
Epoch 18: BCE Loss: 0.1202
KAN Loss: 0.0922, MH-SMoE (SA) Loss: 0.0315
Val Loss: 0.5699 Val BA-Score:  0.800587 Training Time:  18.908591 Inference Time:  0.583252
Epoch 19: BCE Loss: 0.1169
KAN Loss: 0.0886, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.2632 Val BA-Score:  0.954915 Training Time:  18.776817 Inference Time:  0.591578
Epoch 20: BCE Loss: 0.1136
KAN Loss: 0.0849, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.2500 Val BA-Score:  0.961089 Training Time:  18.931232 Inference Time:  0.581927
Epoch 21: BCE Loss: 0.1089
KAN Loss: 0.0803, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.2414 Val BA-Score:  0.962408 Training Time:  19.917431 Inference Time:  0.582606
Epoch 22: BCE Loss: 0.1092
KAN Loss: 0.0757, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.2473 Val BA-Score:  0.966607 Training Time:  18.955190 Inference Time:  0.581584
Epoch 23: BCE Loss: 0.1083
KAN Loss: 0.0699, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2539 Val BA-Score:  0.966147 Training Time:  18.784671 Inference Time:  0.581564
Epoch 24: BCE Loss: 0.1045
KAN Loss: 0.0649, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2767 Val BA-Score:  0.948513 Training Time:  18.964955 Inference Time:  0.582641
Epoch 25: BCE Loss: 0.1030
KAN Loss: 0.0586, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.2569 Val BA-Score:  0.966640 Training Time:  18.826854 Inference Time:  0.580595
Epoch 26: BCE Loss: 0.1014
KAN Loss: 0.0525, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.3255 Val BA-Score:  0.949981 Training Time:  18.908920 Inference Time:  0.581780
Epoch 27: BCE Loss: 0.1014
KAN Loss: 0.0469, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2861 Val BA-Score:  0.968386 Training Time:  18.790012 Inference Time:  0.587577
Epoch 28: BCE Loss: 0.0980
KAN Loss: 0.0408, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2493 Val BA-Score:  0.963284 Training Time:  18.864023 Inference Time:  0.587951
Epoch 29: BCE Loss: 0.0979
KAN Loss: 0.0356, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2608 Val BA-Score:  0.959600 Training Time:  18.775925 Inference Time:  0.582649
Epoch 30: BCE Loss: 0.1005
KAN Loss: 0.0302, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.3091 Val BA-Score:  0.961234 Training Time:  18.905190 Inference Time:  0.583575
Epoch 31: BCE Loss: 0.0952
KAN Loss: 0.0252, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2599 Val BA-Score:  0.961948 Training Time:  18.822025 Inference Time:  0.584181
Epoch 32: BCE Loss: 0.0944
KAN Loss: 0.0212, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2885 Val BA-Score:  0.961267 Training Time:  19.026957 Inference Time:  0.583259
Epoch 33: BCE Loss: 0.0947
KAN Loss: 0.0184, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2705 Val BA-Score:  0.963244 Training Time:  18.861414 Inference Time:  0.576135
Epoch 34: BCE Loss: 0.0934
KAN Loss: 0.0164, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2433 Val BA-Score:  0.962133 Training Time:  18.847931 Inference Time:  0.582269
Epoch 35: BCE Loss: 0.0950
KAN Loss: 0.0153, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2801 Val BA-Score:  0.957077 Training Time:  19.036159 Inference Time:  0.658717
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.966450270348481 0.9759047489400214 0.9863925104070272 0.966450270348481 0.9723544616130522
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     34537
           1       0.99      1.00      0.99      6756
           2       0.98      0.91      0.94      3467

    accuracy                           0.99     44760
   macro avg       0.99      0.97      0.98     44760
weighted avg       0.99      0.99      0.99     44760

Low Quality (Post 2020)
0.8689037153322867 0.8634010814275355 0.8581329693936932 0.8689037153322867 0.9431101386402111
              precision    recall  f1-score   support

           0       1.00      0.99      0.99      1960
           1       0.96      1.00      0.98       235
           2       0.62      0.62      0.62        26

    accuracy                           0.99      2221
   macro avg       0.86      0.87      0.86      2221
weighted avg       0.99      0.99      0.99      2221


High Quality Post 2020
                     mean       std       sem  count
Model                                               
Baseline_no_gMLP  0.97789  0.002035  0.001175      3
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.970189  0.003947  0.002279      3
                     mean       std       sem  count
Model                                               
Baseline_no_gMLP  0.97493  0.002534  0.001463      3

Low Quality Post 2020
                      mean       std      sem  count
Model                                               
Baseline_no_gMLP  0.832997  0.066131  0.03818      3
                     mean       std      sem  count
Model                                              
Baseline_no_gMLP  0.89417  0.033411  0.01929      3
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.905056  0.066143  0.038188      3
*************************Fold:  3 **********************************

Using: cuda:0!
Total Trainable Parameters:  1033761.0
Total Parameters:  1033761.0
Epoch 1: BCE Loss: 0.9716
KAN Loss: 0.0773, MH-SMoE (SA) Loss: 0.1115
Val Loss: 0.8400 Val BA-Score:  0.622500 Training Time:  18.947320 Inference Time:  0.584391
Epoch 2: BCE Loss: 0.4942
KAN Loss: 0.0541, MH-SMoE (SA) Loss: 0.0480
Val Loss: 0.4660 Val BA-Score:  0.942968 Training Time:  20.445992 Inference Time:  0.657926
Epoch 3: BCE Loss: 0.3119
KAN Loss: 0.0531, MH-SMoE (SA) Loss: 0.0410
Val Loss: 0.4273 Val BA-Score:  0.944579 Training Time:  20.262594 Inference Time:  0.582779
Epoch 4: BCE Loss: 0.2427
KAN Loss: 0.0579, MH-SMoE (SA) Loss: 0.0381
Val Loss: 0.3123 Val BA-Score:  0.961058 Training Time:  19.341472 Inference Time:  0.654632
Epoch 5: BCE Loss: 0.1972
KAN Loss: 0.0649, MH-SMoE (SA) Loss: 0.0360
Val Loss: 0.3505 Val BA-Score:  0.946435 Training Time:  21.368083 Inference Time:  0.667726
Epoch 6: BCE Loss: 0.1752
KAN Loss: 0.0727, MH-SMoE (SA) Loss: 0.0348
Val Loss: 0.5168 Val BA-Score:  0.754545 Training Time:  21.509544 Inference Time:  0.660424
Epoch 7: BCE Loss: 0.1655
KAN Loss: 0.0830, MH-SMoE (SA) Loss: 0.0336
Val Loss: 0.2855 Val BA-Score:  0.963879 Training Time:  20.728094 Inference Time:  0.638346
Epoch 8: BCE Loss: 0.1582
KAN Loss: 0.0902, MH-SMoE (SA) Loss: 0.0334
Val Loss: 0.2326 Val BA-Score:  0.965248 Training Time:  20.592384 Inference Time:  0.666100
Epoch 9: BCE Loss: 0.1580
KAN Loss: 0.0978, MH-SMoE (SA) Loss: 0.0326
Val Loss: 0.1760 Val BA-Score:  0.951011 Training Time:  20.224531 Inference Time:  0.583668
Epoch 10: BCE Loss: 0.1518
KAN Loss: 0.1024, MH-SMoE (SA) Loss: 0.0322
Val Loss: 0.1691 Val BA-Score:  0.965159 Training Time:  19.349906 Inference Time:  0.576252
Epoch 11: BCE Loss: 0.1454
KAN Loss: 0.1047, MH-SMoE (SA) Loss: 0.0321
Val Loss: 0.1971 Val BA-Score:  0.966239 Training Time:  22.845705 Inference Time:  0.585371
Epoch 12: BCE Loss: 0.1421
KAN Loss: 0.1052, MH-SMoE (SA) Loss: 0.0318
Val Loss: 0.2354 Val BA-Score:  0.947714 Training Time:  18.964196 Inference Time:  0.584169
Epoch 13: BCE Loss: 0.1387
KAN Loss: 0.1043, MH-SMoE (SA) Loss: 0.0317
Val Loss: 0.3316 Val BA-Score:  0.852464 Training Time:  18.846846 Inference Time:  0.585704
Epoch 14: BCE Loss: 0.1357
KAN Loss: 0.1030, MH-SMoE (SA) Loss: 0.0314
Val Loss: 0.2856 Val BA-Score:  0.960863 Training Time:  21.069382 Inference Time:  0.664310
Epoch 15: BCE Loss: 0.1313
KAN Loss: 0.1007, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.2988 Val BA-Score:  0.885017 Training Time:  21.299088 Inference Time:  0.677334
Epoch 16: BCE Loss: 0.1270
KAN Loss: 0.0979, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.2147 Val BA-Score:  0.970251 Training Time:  21.477366 Inference Time:  0.660047
Epoch 17: BCE Loss: 0.1240
KAN Loss: 0.0949, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.8608 Val BA-Score:  0.550404 Training Time:  20.774611 Inference Time:  0.663051
Epoch 18: BCE Loss: 0.1209
KAN Loss: 0.0916, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.2344 Val BA-Score:  0.970294 Training Time:  21.734418 Inference Time:  0.678380
Epoch 19: BCE Loss: 0.1202
KAN Loss: 0.0885, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.3023 Val BA-Score:  0.939809 Training Time:  21.353562 Inference Time:  0.666590
Epoch 20: BCE Loss: 0.1159
KAN Loss: 0.0836, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.2408 Val BA-Score:  0.958436 Training Time:  21.022599 Inference Time:  0.657652
Epoch 21: BCE Loss: 0.1119
KAN Loss: 0.0793, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2496 Val BA-Score:  0.967232 Training Time:  20.982073 Inference Time:  0.671670
Epoch 22: BCE Loss: 0.1139
KAN Loss: 0.0751, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2746 Val BA-Score:  0.970261 Training Time:  21.323373 Inference Time:  0.667555
Epoch 23: BCE Loss: 0.1089
KAN Loss: 0.0700, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.2004 Val BA-Score:  0.964852 Training Time:  21.164429 Inference Time:  0.596572
Epoch 24: BCE Loss: 0.1054
KAN Loss: 0.0632, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2438 Val BA-Score:  0.969504 Training Time:  20.949088 Inference Time:  0.675026
Epoch 25: BCE Loss: 0.1043
KAN Loss: 0.0577, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.1898 Val BA-Score:  0.969196 Training Time:  21.299502 Inference Time:  0.667987
Epoch 26: BCE Loss: 0.1030
KAN Loss: 0.0516, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2214 Val BA-Score:  0.962517 Training Time:  21.548596 Inference Time:  0.676122
Epoch 27: BCE Loss: 0.1008
KAN Loss: 0.0465, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2193 Val BA-Score:  0.962956 Training Time:  20.952482 Inference Time:  0.588131
Epoch 28: BCE Loss: 0.0997
KAN Loss: 0.0412, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2083 Val BA-Score:  0.958063 Training Time:  19.132676 Inference Time:  0.583988
Epoch 29: BCE Loss: 0.0982
KAN Loss: 0.0360, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2236 Val BA-Score:  0.971193 Training Time:  18.897578 Inference Time:  0.584028
Epoch 30: BCE Loss: 0.0973
KAN Loss: 0.0305, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2216 Val BA-Score:  0.960169 Training Time:  19.028856 Inference Time:  0.579173
Epoch 31: BCE Loss: 0.0967
KAN Loss: 0.0258, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2416 Val BA-Score:  0.965698 Training Time:  19.861657 Inference Time:  0.643660
Epoch 32: BCE Loss: 0.0963
KAN Loss: 0.0221, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2562 Val BA-Score:  0.961475 Training Time:  20.464804 Inference Time:  0.629235
Epoch 33: BCE Loss: 0.0967
KAN Loss: 0.0194, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2222 Val BA-Score:  0.965271 Training Time:  20.310499 Inference Time:  0.631874
Epoch 34: BCE Loss: 0.0976
KAN Loss: 0.0175, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2395 Val BA-Score:  0.965665 Training Time:  20.433442 Inference Time:  0.593494
Epoch 35: BCE Loss: 0.0941
KAN Loss: 0.0165, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2317 Val BA-Score:  0.965840 Training Time:  20.614726 Inference Time:  0.637434
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.9699083337015271 0.9779011823979542 0.9867900870139207 0.9699083337015271 0.9751338025640541
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     34537
           1       0.98      1.00      0.99      6756
           2       0.98      0.91      0.95      3467

    accuracy                           0.99     44760
   macro avg       0.99      0.97      0.98     44760
weighted avg       0.99      0.99      0.99     44760

Low Quality (Post 2020)
0.8668628990057562 0.8239070810762285 0.7933471825388173 0.8668628990057562 0.9202284295621402
              precision    recall  f1-score   support

           0       1.00      0.99      0.99      1960
           1       0.96      1.00      0.98       235
           2       0.42      0.62      0.50        26

    accuracy                           0.98      2221
   macro avg       0.79      0.87      0.82      2221
weighted avg       0.99      0.98      0.98      2221


High Quality Post 2020
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.977892  0.001662  0.000831      4
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.970119  0.003225  0.001613      4
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.974981  0.002072  0.001036      4

Low Quality Post 2020
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.830725  0.054186  0.027093      4
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.887343  0.030506  0.015253      4
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.908849  0.054536  0.027268      4
*************************Fold:  4 **********************************

Using: cuda:0!
Total Trainable Parameters:  1033761.0
Total Parameters:  1033761.0
Epoch 1: BCE Loss: 0.9719
KAN Loss: 0.0775, MH-SMoE (SA) Loss: 0.1361
Val Loss: 0.8027 Val BA-Score:  0.750118 Training Time:  20.251807 Inference Time:  0.636373
Epoch 2: BCE Loss: 0.5681
KAN Loss: 0.0546, MH-SMoE (SA) Loss: 0.0501
Val Loss: 0.5824 Val BA-Score:  0.882699 Training Time:  20.401337 Inference Time:  0.620668
Epoch 3: BCE Loss: 0.3309
KAN Loss: 0.0535, MH-SMoE (SA) Loss: 0.0437
Val Loss: 0.5198 Val BA-Score:  0.931685 Training Time:  20.137141 Inference Time:  0.670056
Epoch 4: BCE Loss: 0.2162
KAN Loss: 0.0580, MH-SMoE (SA) Loss: 0.0386
Val Loss: 0.4833 Val BA-Score:  0.949280 Training Time:  20.639280 Inference Time:  0.635683
Epoch 5: BCE Loss: 0.1924
KAN Loss: 0.0651, MH-SMoE (SA) Loss: 0.0370
Val Loss: 0.3341 Val BA-Score:  0.954024 Training Time:  20.344024 Inference Time:  0.639604
Epoch 6: BCE Loss: 0.1735
KAN Loss: 0.0738, MH-SMoE (SA) Loss: 0.0353
Val Loss: 0.2346 Val BA-Score:  0.964160 Training Time:  20.469560 Inference Time:  0.634279
Epoch 7: BCE Loss: 0.1692
KAN Loss: 0.0828, MH-SMoE (SA) Loss: 0.0343
Val Loss: 0.3394 Val BA-Score:  0.963403 Training Time:  20.666674 Inference Time:  0.577212
Epoch 8: BCE Loss: 0.1637
KAN Loss: 0.0903, MH-SMoE (SA) Loss: 0.0337
Val Loss: 0.4260 Val BA-Score:  0.892906 Training Time:  20.724254 Inference Time:  0.631426
Epoch 9: BCE Loss: 0.1543
KAN Loss: 0.0967, MH-SMoE (SA) Loss: 0.0331
Val Loss: 0.2725 Val BA-Score:  0.960924 Training Time:  20.216570 Inference Time:  0.642458
Epoch 10: BCE Loss: 0.1744
KAN Loss: 0.1007, MH-SMoE (SA) Loss: 0.0328
Val Loss: 0.2153 Val BA-Score:  0.964061 Training Time:  20.348398 Inference Time:  0.636441
Epoch 11: BCE Loss: 0.1423
KAN Loss: 0.1029, MH-SMoE (SA) Loss: 0.0321
Val Loss: 0.2066 Val BA-Score:  0.961648 Training Time:  20.093126 Inference Time:  0.611416
Epoch 12: BCE Loss: 0.1416
KAN Loss: 0.1034, MH-SMoE (SA) Loss: 0.0320
Val Loss: 0.2373 Val BA-Score:  0.960146 Training Time:  20.247050 Inference Time:  0.621449
Epoch 13: BCE Loss: 0.1374
KAN Loss: 0.1027, MH-SMoE (SA) Loss: 0.0317
Val Loss: 0.4115 Val BA-Score:  0.839438 Training Time:  20.357007 Inference Time:  0.644779
Epoch 14: BCE Loss: 0.1348
KAN Loss: 0.1020, MH-SMoE (SA) Loss: 0.0316
Val Loss: 0.2047 Val BA-Score:  0.964481 Training Time:  20.298008 Inference Time:  0.638921
Epoch 15: BCE Loss: 0.1268
KAN Loss: 0.1001, MH-SMoE (SA) Loss: 0.0315
Val Loss: 0.2423 Val BA-Score:  0.962855 Training Time:  20.309426 Inference Time:  0.640200
Epoch 16: BCE Loss: 0.1303
KAN Loss: 0.0979, MH-SMoE (SA) Loss: 0.0315
Val Loss: 0.2257 Val BA-Score:  0.963459 Training Time:  20.716026 Inference Time:  0.676499
Epoch 17: BCE Loss: 0.1261
KAN Loss: 0.0951, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.5003 Val BA-Score:  0.694789 Training Time:  20.603033 Inference Time:  0.632967
Epoch 18: BCE Loss: 0.1251
KAN Loss: 0.0919, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.3439 Val BA-Score:  0.960126 Training Time:  20.184332 Inference Time:  0.635506
Epoch 19: BCE Loss: 0.1155
KAN Loss: 0.0886, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.2279 Val BA-Score:  0.961320 Training Time:  20.216277 Inference Time:  0.631108
Epoch 20: BCE Loss: 0.1157
KAN Loss: 0.0849, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.3080 Val BA-Score:  0.962319 Training Time:  20.309334 Inference Time:  0.681902
Epoch 21: BCE Loss: 0.1111
KAN Loss: 0.0799, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.2649 Val BA-Score:  0.962560 Training Time:  20.596213 Inference Time:  0.655069
Epoch 22: BCE Loss: 0.1091
KAN Loss: 0.0751, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2568 Val BA-Score:  0.961452 Training Time:  20.271490 Inference Time:  0.635418
Epoch 23: BCE Loss: 0.1072
KAN Loss: 0.0700, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2768 Val BA-Score:  0.968165 Training Time:  20.389683 Inference Time:  0.639838
Epoch 24: BCE Loss: 0.1061
KAN Loss: 0.0649, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.2570 Val BA-Score:  0.966788 Training Time:  20.109383 Inference Time:  0.576468
Epoch 25: BCE Loss: 0.1042
KAN Loss: 0.0592, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.3285 Val BA-Score:  0.964336 Training Time:  20.780500 Inference Time:  0.625271
Epoch 26: BCE Loss: 0.1007
KAN Loss: 0.0527, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2732 Val BA-Score:  0.966071 Training Time:  20.285442 Inference Time:  0.640157
Epoch 27: BCE Loss: 0.0993
KAN Loss: 0.0477, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.3048 Val BA-Score:  0.962913 Training Time:  20.274334 Inference Time:  0.628525
Epoch 28: BCE Loss: 0.0985
KAN Loss: 0.0425, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2789 Val BA-Score:  0.964798 Training Time:  20.383185 Inference Time:  0.638201
Epoch 29: BCE Loss: 0.0965
KAN Loss: 0.0370, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2673 Val BA-Score:  0.963724 Training Time:  18.993138 Inference Time:  0.584410
Epoch 30: BCE Loss: 0.0950
KAN Loss: 0.0312, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2552 Val BA-Score:  0.964557 Training Time:  19.016977 Inference Time:  0.579170
Epoch 31: BCE Loss: 0.0944
KAN Loss: 0.0261, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2738 Val BA-Score:  0.962956 Training Time:  18.801055 Inference Time:  0.586418
Epoch 32: BCE Loss: 0.0962
KAN Loss: 0.0220, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2875 Val BA-Score:  0.966127 Training Time:  19.039646 Inference Time:  0.587246
Epoch 33: BCE Loss: 0.0926
KAN Loss: 0.0189, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2966 Val BA-Score:  0.964788 Training Time:  18.865849 Inference Time:  0.583476
Epoch 34: BCE Loss: 0.0930
KAN Loss: 0.0167, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.3023 Val BA-Score:  0.958406 Training Time:  19.843068 Inference Time:  0.581129
Epoch 35: BCE Loss: 0.0930
KAN Loss: 0.0156, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2754 Val BA-Score:  0.966795 Training Time:  18.783834 Inference Time:  0.578474
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.9727997901137363 0.9796621895347336 0.9872196539042181 0.9727997901137363 0.9769348243220506
              precision    recall  f1-score   support

           0       0.99      1.00      1.00     34537
           1       0.98      1.00      0.99      6756
           2       0.98      0.92      0.95      3467

    accuracy                           0.99     44760
   macro avg       0.99      0.97      0.98     44760
weighted avg       0.99      0.99      0.99     44760

Low Quality (Post 2020)
0.8815541601255887 0.8681483293366048 0.8555553419375976 0.8815541601255887 0.9433947853413933
              precision    recall  f1-score   support

           0       1.00      0.99      0.99      1960
           1       0.96      1.00      0.98       235
           2       0.61      0.65      0.63        26

    accuracy                           0.99      2221
   macro avg       0.86      0.88      0.87      2221
weighted avg       0.99      0.99      0.99      2221


High Quality Post 2020
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.978246  0.001642  0.000735      5
                      mean      std       sem  count
Model                                               
Baseline_no_gMLP  0.970655  0.00304  0.001359      5
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.975372  0.001996  0.000892      5

Low Quality Post 2020
                     mean       std       sem  count
Model                                               
Baseline_no_gMLP  0.83821  0.049822  0.022281      5
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.886185  0.026545  0.011871      5
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.915758  0.049692  0.022223      5
*************************Fold:  5 **********************************

Using: cuda:0!
Total Trainable Parameters:  1033761.0
Total Parameters:  1033761.0
Epoch 1: BCE Loss: 0.9541
KAN Loss: 0.0778, MH-SMoE (SA) Loss: 0.1292
Val Loss: 0.7672 Val BA-Score:  0.666751 Training Time:  18.857509 Inference Time:  0.583308
Epoch 2: BCE Loss: 0.5076
KAN Loss: 0.0547, MH-SMoE (SA) Loss: 0.0550
Val Loss: 0.5964 Val BA-Score:  0.848960 Training Time:  18.870996 Inference Time:  0.589398
Epoch 3: BCE Loss: 0.3346
KAN Loss: 0.0536, MH-SMoE (SA) Loss: 0.0421
Val Loss: 0.4583 Val BA-Score:  0.942629 Training Time:  18.917699 Inference Time:  0.585629
Epoch 4: BCE Loss: 0.2346
KAN Loss: 0.0579, MH-SMoE (SA) Loss: 0.0386
Val Loss: 0.3899 Val BA-Score:  0.943038 Training Time:  18.855056 Inference Time:  0.586135
Epoch 5: BCE Loss: 0.1958
KAN Loss: 0.0647, MH-SMoE (SA) Loss: 0.0364
Val Loss: 0.2672 Val BA-Score:  0.961102 Training Time:  19.008609 Inference Time:  0.582724
Epoch 6: BCE Loss: 0.1691
KAN Loss: 0.0726, MH-SMoE (SA) Loss: 0.0348
Val Loss: 0.2703 Val BA-Score:  0.943851 Training Time:  19.113989 Inference Time:  0.579135
Epoch 7: BCE Loss: 0.1743
KAN Loss: 0.0814, MH-SMoE (SA) Loss: 0.0342
Val Loss: 0.3769 Val BA-Score:  0.956942 Training Time:  18.880523 Inference Time:  0.581926
Epoch 8: BCE Loss: 0.1580
KAN Loss: 0.0898, MH-SMoE (SA) Loss: 0.0334
Val Loss: 0.1937 Val BA-Score:  0.961594 Training Time:  18.928428 Inference Time:  0.581665
Epoch 9: BCE Loss: 0.1531
KAN Loss: 0.0973, MH-SMoE (SA) Loss: 0.0326
Val Loss: 0.1803 Val BA-Score:  0.965172 Training Time:  18.897424 Inference Time:  0.587690
Epoch 10: BCE Loss: 0.1505
KAN Loss: 0.1019, MH-SMoE (SA) Loss: 0.0322
Val Loss: 0.2364 Val BA-Score:  0.947138 Training Time:  18.971560 Inference Time:  0.582994
Epoch 11: BCE Loss: 0.1450
KAN Loss: 0.1036, MH-SMoE (SA) Loss: 0.0320
Val Loss: 0.3532 Val BA-Score:  0.962077 Training Time:  18.880440 Inference Time:  0.584183
Epoch 12: BCE Loss: 0.1396
KAN Loss: 0.1037, MH-SMoE (SA) Loss: 0.0320
Val Loss: 0.2554 Val BA-Score:  0.954836 Training Time:  18.972469 Inference Time:  0.582793
Epoch 13: BCE Loss: 0.1335
KAN Loss: 0.1029, MH-SMoE (SA) Loss: 0.0317
Val Loss: 0.3777 Val BA-Score:  0.927666 Training Time:  18.945980 Inference Time:  0.585211
Epoch 14: BCE Loss: 0.1346
KAN Loss: 0.1020, MH-SMoE (SA) Loss: 0.0314
Val Loss: 0.2719 Val BA-Score:  0.953929 Training Time:  18.953242 Inference Time:  0.581879
Epoch 15: BCE Loss: 0.1293
KAN Loss: 0.1002, MH-SMoE (SA) Loss: 0.0314
Val Loss: 0.2396 Val BA-Score:  0.962702 Training Time:  18.874769 Inference Time:  0.584284
Epoch 16: BCE Loss: 0.1250
KAN Loss: 0.0979, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.2767 Val BA-Score:  0.954826 Training Time:  18.860911 Inference Time:  0.582084
Epoch 17: BCE Loss: 0.1206
KAN Loss: 0.0951, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.2354 Val BA-Score:  0.965939 Training Time:  19.886255 Inference Time:  0.577495
Epoch 18: BCE Loss: 0.1180
KAN Loss: 0.0920, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.2123 Val BA-Score:  0.963022 Training Time:  19.062074 Inference Time:  0.584356
Epoch 19: BCE Loss: 0.1156
KAN Loss: 0.0891, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.3312 Val BA-Score:  0.958053 Training Time:  18.896964 Inference Time:  0.578071
Epoch 20: BCE Loss: 0.1151
KAN Loss: 0.0847, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.2052 Val BA-Score:  0.962494 Training Time:  18.892803 Inference Time:  0.583498
Epoch 21: BCE Loss: 0.1094
KAN Loss: 0.0800, MH-SMoE (SA) Loss: 0.0309
Val Loss: 0.2709 Val BA-Score:  0.947623 Training Time:  18.922107 Inference Time:  0.582080
Epoch 22: BCE Loss: 0.1077
KAN Loss: 0.0748, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.1736 Val BA-Score:  0.959600 Training Time:  18.913278 Inference Time:  0.586664
Epoch 23: BCE Loss: 0.1054
KAN Loss: 0.0694, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.2367 Val BA-Score:  0.962944 Training Time:  18.993569 Inference Time:  0.582447
Epoch 24: BCE Loss: 0.1030
KAN Loss: 0.0648, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2349 Val BA-Score:  0.968279 Training Time:  18.890357 Inference Time:  0.583644
Epoch 25: BCE Loss: 0.1019
KAN Loss: 0.0585, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2635 Val BA-Score:  0.961683 Training Time:  19.028099 Inference Time:  0.580034
Epoch 26: BCE Loss: 0.1000
KAN Loss: 0.0529, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2787 Val BA-Score:  0.962004 Training Time:  18.876162 Inference Time:  0.586477
Epoch 27: BCE Loss: 0.0960
KAN Loss: 0.0471, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2436 Val BA-Score:  0.962870 Training Time:  18.968890 Inference Time:  0.584825
Epoch 28: BCE Loss: 0.0964
KAN Loss: 0.0418, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2320 Val BA-Score:  0.968078 Training Time:  18.879961 Inference Time:  0.588599
Epoch 29: BCE Loss: 0.0961
KAN Loss: 0.0362, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2233 Val BA-Score:  0.968111 Training Time:  18.946308 Inference Time:  0.586708
Epoch 30: BCE Loss: 0.0948
KAN Loss: 0.0303, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2284 Val BA-Score:  0.966927 Training Time:  19.023105 Inference Time:  0.583651
Epoch 31: BCE Loss: 0.0929
KAN Loss: 0.0252, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2767 Val BA-Score:  0.962354 Training Time:  19.017024 Inference Time:  0.585185
Epoch 32: BCE Loss: 0.0940
KAN Loss: 0.0210, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2569 Val BA-Score:  0.965347 Training Time:  18.920803 Inference Time:  0.580217
Epoch 33: BCE Loss: 0.0914
KAN Loss: 0.0180, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2627 Val BA-Score:  0.965535 Training Time:  19.013297 Inference Time:  0.582909
Epoch 34: BCE Loss: 0.0916
KAN Loss: 0.0159, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2479 Val BA-Score:  0.969427 Training Time:  18.959979 Inference Time:  0.581680
Epoch 35: BCE Loss: 0.0915
KAN Loss: 0.0148, MH-SMoE (SA) Loss: 0.0303
Val Loss: 0.2461 Val BA-Score:  0.960632 Training Time:  18.987877 Inference Time:  0.583010
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.9704755498255299 0.9781924723049964 0.9867561253973504 0.9704755498255299 0.9754347812661723
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     34537
           1       0.98      1.00      0.99      6756
           2       0.98      0.92      0.95      3467

    accuracy                           0.99     44760
   macro avg       0.99      0.97      0.98     44760
weighted avg       0.99      0.99      0.99     44760

Low Quality (Post 2020)
0.8930141287284145 0.8505355665839537 0.8186969633214111 0.8930141287284145 0.9303470715080057
              precision    recall  f1-score   support

           0       1.00      0.99      0.99      1960
           1       0.96      1.00      0.98       235
           2       0.50      0.69      0.58        26

    accuracy                           0.98      2221
   macro avg       0.82      0.89      0.85      2221
weighted avg       0.99      0.98      0.99      2221


High Quality Post 2020
                      mean       std     sem  count
Model                                              
Baseline_no_gMLP  0.978237  0.001469  0.0006      6
                      mean      std      sem  count
Model                                              
Baseline_no_gMLP  0.970625  0.00272  0.00111      6
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.975382  0.001785  0.000729      6

Low Quality Post 2020
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.840264  0.044845  0.018308      6
                      mean       std      sem  count
Model                                               
Baseline_no_gMLP  0.887323  0.023906  0.00976      6
                     mean       std       sem  count
Model                                               
Baseline_no_gMLP  0.91819  0.044843  0.018307      6
*************************Fold:  6 **********************************

Using: cuda:0!
Total Trainable Parameters:  1033761.0
Total Parameters:  1033761.0
Epoch 1: BCE Loss: 1.0228
KAN Loss: 0.0774, MH-SMoE (SA) Loss: 0.0966
Val Loss: 0.8668 Val BA-Score:  0.653123 Training Time:  18.933000 Inference Time:  0.584217
Epoch 2: BCE Loss: 0.4758
KAN Loss: 0.0535, MH-SMoE (SA) Loss: 0.0450
Val Loss: 0.4683 Val BA-Score:  0.898147 Training Time:  18.882709 Inference Time:  0.584783
Epoch 3: BCE Loss: 0.3011
KAN Loss: 0.0530, MH-SMoE (SA) Loss: 0.0399
Val Loss: 0.4709 Val BA-Score:  0.942376 Training Time:  19.885518 Inference Time:  0.583175
Epoch 4: BCE Loss: 0.2291
KAN Loss: 0.0573, MH-SMoE (SA) Loss: 0.0379
Val Loss: 0.3689 Val BA-Score:  0.955530 Training Time:  18.934948 Inference Time:  0.585160
Epoch 5: BCE Loss: 0.1917
KAN Loss: 0.0653, MH-SMoE (SA) Loss: 0.0363
Val Loss: 0.2581 Val BA-Score:  0.962692 Training Time:  18.983131 Inference Time:  0.586706
Epoch 6: BCE Loss: 0.1770
KAN Loss: 0.0735, MH-SMoE (SA) Loss: 0.0352
Val Loss: 0.2685 Val BA-Score:  0.956460 Training Time:  19.050102 Inference Time:  0.581647
Epoch 7: BCE Loss: 0.1652
KAN Loss: 0.0828, MH-SMoE (SA) Loss: 0.0340
Val Loss: 0.2237 Val BA-Score:  0.963932 Training Time:  18.897509 Inference Time:  0.583181
Epoch 8: BCE Loss: 0.1607
KAN Loss: 0.0907, MH-SMoE (SA) Loss: 0.0332
Val Loss: 0.2049 Val BA-Score:  0.962219 Training Time:  18.953675 Inference Time:  0.583506
Epoch 9: BCE Loss: 0.1502
KAN Loss: 0.0973, MH-SMoE (SA) Loss: 0.0328
Val Loss: 0.4947 Val BA-Score:  0.795334 Training Time:  18.952791 Inference Time:  0.584150
Epoch 10: BCE Loss: 0.1520
KAN Loss: 0.1021, MH-SMoE (SA) Loss: 0.0326
Val Loss: 0.1930 Val BA-Score:  0.955362 Training Time:  19.065409 Inference Time:  0.582902
Epoch 11: BCE Loss: 0.1478
KAN Loss: 0.1042, MH-SMoE (SA) Loss: 0.0320
Val Loss: 0.2579 Val BA-Score:  0.950054 Training Time:  18.928227 Inference Time:  0.587774
Epoch 12: BCE Loss: 0.1362
KAN Loss: 0.1042, MH-SMoE (SA) Loss: 0.0318
Val Loss: 0.3088 Val BA-Score:  0.936629 Training Time:  18.993862 Inference Time:  0.584116
Epoch 13: BCE Loss: 0.1362
KAN Loss: 0.1031, MH-SMoE (SA) Loss: 0.0318
Val Loss: 0.2115 Val BA-Score:  0.968716 Training Time:  18.875611 Inference Time:  0.587756
Epoch 14: BCE Loss: 0.1325
KAN Loss: 0.1021, MH-SMoE (SA) Loss: 0.0316
Val Loss: 0.2393 Val BA-Score:  0.958393 Training Time:  18.966219 Inference Time:  0.584201
Epoch 15: BCE Loss: 0.1251
KAN Loss: 0.1001, MH-SMoE (SA) Loss: 0.0315
Val Loss: 0.2698 Val BA-Score:  0.965075 Training Time:  18.891766 Inference Time:  0.589081
Epoch 16: BCE Loss: 0.1272
KAN Loss: 0.0976, MH-SMoE (SA) Loss: 0.0316
Val Loss: 0.2089 Val BA-Score:  0.967288 Training Time:  18.993674 Inference Time:  0.582446
Epoch 17: BCE Loss: 0.1235
KAN Loss: 0.0949, MH-SMoE (SA) Loss: 0.0314
Val Loss: 0.2247 Val BA-Score:  0.968736 Training Time:  18.927800 Inference Time:  0.589466
Epoch 18: BCE Loss: 0.1234
KAN Loss: 0.0923, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.4201 Val BA-Score:  0.861267 Training Time:  19.055089 Inference Time:  0.586520
Epoch 19: BCE Loss: 0.1207
KAN Loss: 0.0887, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.2811 Val BA-Score:  0.969120 Training Time:  18.950279 Inference Time:  0.584236
Epoch 20: BCE Loss: 0.1147
KAN Loss: 0.0842, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.2954 Val BA-Score:  0.960096 Training Time:  19.061557 Inference Time:  0.587673
Epoch 21: BCE Loss: 0.1124
KAN Loss: 0.0798, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.3074 Val BA-Score:  0.966501 Training Time:  18.878899 Inference Time:  0.586840
Epoch 22: BCE Loss: 0.1112
KAN Loss: 0.0749, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2902 Val BA-Score:  0.964427 Training Time:  18.998061 Inference Time:  0.586738
Epoch 23: BCE Loss: 0.1075
KAN Loss: 0.0690, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2522 Val BA-Score:  0.963747 Training Time:  18.943726 Inference Time:  0.587298
Epoch 24: BCE Loss: 0.1049
KAN Loss: 0.0632, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2948 Val BA-Score:  0.959338 Training Time:  19.048813 Inference Time:  0.566010
Epoch 25: BCE Loss: 0.1051
KAN Loss: 0.0581, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.3025 Val BA-Score:  0.965370 Training Time:  19.138868 Inference Time:  0.577146
Epoch 26: BCE Loss: 0.1026
KAN Loss: 0.0516, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2753 Val BA-Score:  0.953571 Training Time:  19.058907 Inference Time:  0.584685
Epoch 27: BCE Loss: 0.1017
KAN Loss: 0.0461, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.3262 Val BA-Score:  0.954262 Training Time:  18.906963 Inference Time:  0.581107
Epoch 28: BCE Loss: 0.0996
KAN Loss: 0.0415, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2949 Val BA-Score:  0.968244 Training Time:  18.993877 Inference Time:  0.583746
Epoch 29: BCE Loss: 0.0988
KAN Loss: 0.0360, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2783 Val BA-Score:  0.962903 Training Time:  18.921783 Inference Time:  0.582873
Epoch 30: BCE Loss: 0.0973
KAN Loss: 0.0305, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2739 Val BA-Score:  0.965294 Training Time:  18.913283 Inference Time:  0.588379
Epoch 31: BCE Loss: 0.0957
KAN Loss: 0.0257, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2584 Val BA-Score:  0.972215 Training Time:  18.922957 Inference Time:  0.583853
Epoch 32: BCE Loss: 0.0970
KAN Loss: 0.0221, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2781 Val BA-Score:  0.968749 Training Time:  18.907909 Inference Time:  0.585528
Epoch 33: BCE Loss: 0.0965
KAN Loss: 0.0193, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2770 Val BA-Score:  0.966425 Training Time:  18.963833 Inference Time:  0.582076
Epoch 34: BCE Loss: 0.0949
KAN Loss: 0.0175, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.3006 Val BA-Score:  0.964692 Training Time:  19.032681 Inference Time:  0.578598
Epoch 35: BCE Loss: 0.0946
KAN Loss: 0.0164, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2886 Val BA-Score:  0.962278 Training Time:  18.914313 Inference Time:  0.581648
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.9733105490106632 0.9798712861145721 0.9870846800956296 0.9733105490106632 0.9771767080658581
              precision    recall  f1-score   support

           0       0.99      1.00      1.00     34537
           1       0.98      1.00      0.99      6756
           2       0.98      0.92      0.95      3467

    accuracy                           0.99     44760
   macro avg       0.99      0.97      0.98     44760
weighted avg       0.99      0.99      0.99     44760

Low Quality (Post 2020)
0.8940345368916797 0.8687111257690173 0.8468922225670398 0.8940345368916797 0.9417584169060041
              precision    recall  f1-score   support

           0       1.00      0.99      0.99      1960
           1       0.96      1.00      0.98       235
           2       0.58      0.69      0.63        26

    accuracy                           0.99      2221
   macro avg       0.85      0.89      0.87      2221
weighted avg       0.99      0.99      0.99      2221


High Quality Post 2020
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.978471  0.001477  0.000558      7
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.971009  0.002682  0.001014      7
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.975639  0.001765  0.000667      7

Low Quality Post 2020
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.844328  0.042326  0.015998      7
                      mean      std       sem  count
Model                                               
Baseline_no_gMLP  0.888282  0.02197  0.008304      7
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.921557  0.041894  0.015834      7
*************************Fold:  7 **********************************

Using: cuda:0!
Total Trainable Parameters:  1033761.0
Total Parameters:  1033761.0
Epoch 1: BCE Loss: 1.0569
KAN Loss: 0.0775, MH-SMoE (SA) Loss: 0.1596
Val Loss: 1.0099 Val BA-Score:  0.553455 Training Time:  18.804851 Inference Time:  0.577893
Epoch 2: BCE Loss: 0.5514
KAN Loss: 0.0537, MH-SMoE (SA) Loss: 0.0574
Val Loss: 0.5042 Val BA-Score:  0.881683 Training Time:  18.924232 Inference Time:  0.581227
Epoch 3: BCE Loss: 0.3235
KAN Loss: 0.0540, MH-SMoE (SA) Loss: 0.0428
Val Loss: 0.4175 Val BA-Score:  0.942799 Training Time:  18.752302 Inference Time:  0.584061
Epoch 4: BCE Loss: 0.2253
KAN Loss: 0.0578, MH-SMoE (SA) Loss: 0.0393
Val Loss: 0.3400 Val BA-Score:  0.953241 Training Time:  18.752534 Inference Time:  0.581591
Epoch 5: BCE Loss: 0.1887
KAN Loss: 0.0632, MH-SMoE (SA) Loss: 0.0370
Val Loss: 0.3005 Val BA-Score:  0.961290 Training Time:  18.932430 Inference Time:  0.577330
Epoch 6: BCE Loss: 0.1986
KAN Loss: 0.0717, MH-SMoE (SA) Loss: 0.0355
Val Loss: 0.3178 Val BA-Score:  0.957308 Training Time:  18.812637 Inference Time:  0.584055
Epoch 7: BCE Loss: 0.1632
KAN Loss: 0.0817, MH-SMoE (SA) Loss: 0.0347
Val Loss: 0.3752 Val BA-Score:  0.940840 Training Time:  18.900348 Inference Time:  0.587732
Epoch 8: BCE Loss: 0.1597
KAN Loss: 0.0895, MH-SMoE (SA) Loss: 0.0335
Val Loss: 0.4340 Val BA-Score:  0.906244 Training Time:  18.893159 Inference Time:  0.576365
Epoch 9: BCE Loss: 0.1569
KAN Loss: 0.0960, MH-SMoE (SA) Loss: 0.0330
Val Loss: 0.2940 Val BA-Score:  0.962758 Training Time:  18.881068 Inference Time:  0.586003
Epoch 10: BCE Loss: 0.1505
KAN Loss: 0.1006, MH-SMoE (SA) Loss: 0.0327
Val Loss: 0.3515 Val BA-Score:  0.934670 Training Time:  18.855220 Inference Time:  0.583327
Epoch 11: BCE Loss: 0.1441
KAN Loss: 0.1028, MH-SMoE (SA) Loss: 0.0325
Val Loss: 0.2961 Val BA-Score:  0.938016 Training Time:  18.918684 Inference Time:  0.587106
Epoch 12: BCE Loss: 0.1381
KAN Loss: 0.1034, MH-SMoE (SA) Loss: 0.0321
Val Loss: 0.3394 Val BA-Score:  0.947463 Training Time:  18.838887 Inference Time:  0.585755
Epoch 13: BCE Loss: 0.1349
KAN Loss: 0.1028, MH-SMoE (SA) Loss: 0.0318
Val Loss: 0.2085 Val BA-Score:  0.964249 Training Time:  18.929790 Inference Time:  0.585853
Epoch 14: BCE Loss: 0.1331
KAN Loss: 0.1019, MH-SMoE (SA) Loss: 0.0317
Val Loss: 0.2383 Val BA-Score:  0.954090 Training Time:  19.092935 Inference Time:  0.581152
Epoch 15: BCE Loss: 0.1270
KAN Loss: 0.1001, MH-SMoE (SA) Loss: 0.0315
Val Loss: 0.2696 Val BA-Score:  0.963101 Training Time:  18.871869 Inference Time:  0.583354
Epoch 16: BCE Loss: 0.1258
KAN Loss: 0.0977, MH-SMoE (SA) Loss: 0.0314
Val Loss: 0.2593 Val BA-Score:  0.964974 Training Time:  18.882059 Inference Time:  0.586452
Epoch 17: BCE Loss: 0.1212
KAN Loss: 0.0952, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.2580 Val BA-Score:  0.963099 Training Time:  18.879639 Inference Time:  0.583550
Epoch 18: BCE Loss: 0.1187
KAN Loss: 0.0921, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.3606 Val BA-Score:  0.935636 Training Time:  18.942254 Inference Time:  0.586854
Epoch 19: BCE Loss: 0.1193
KAN Loss: 0.0888, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.3372 Val BA-Score:  0.962565 Training Time:  18.877517 Inference Time:  0.584823
Epoch 20: BCE Loss: 0.1145
KAN Loss: 0.0842, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.2398 Val BA-Score:  0.961046 Training Time:  18.898948 Inference Time:  0.586299
Epoch 21: BCE Loss: 0.1116
KAN Loss: 0.0798, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.2717 Val BA-Score:  0.965330 Training Time:  18.859322 Inference Time:  0.587881
Epoch 22: BCE Loss: 0.1085
KAN Loss: 0.0752, MH-SMoE (SA) Loss: 0.0309
Val Loss: 0.2796 Val BA-Score:  0.965182 Training Time:  18.922047 Inference Time:  0.584857
Epoch 23: BCE Loss: 0.1070
KAN Loss: 0.0704, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2593 Val BA-Score:  0.966114 Training Time:  18.840223 Inference Time:  0.582590
Epoch 24: BCE Loss: 0.1048
KAN Loss: 0.0641, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2897 Val BA-Score:  0.966597 Training Time:  18.910300 Inference Time:  0.585843
Epoch 25: BCE Loss: 0.1025
KAN Loss: 0.0587, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.2431 Val BA-Score:  0.964150 Training Time:  18.970337 Inference Time:  0.577767
Epoch 26: BCE Loss: 0.0998
KAN Loss: 0.0524, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.3163 Val BA-Score:  0.965116 Training Time:  18.933133 Inference Time:  0.583446
Epoch 27: BCE Loss: 0.0983
KAN Loss: 0.0466, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2677 Val BA-Score:  0.964216 Training Time:  18.818708 Inference Time:  0.589261
Epoch 28: BCE Loss: 0.1002
KAN Loss: 0.0413, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.3053 Val BA-Score:  0.961770 Training Time:  18.937454 Inference Time:  0.586277
Epoch 29: BCE Loss: 0.0977
KAN Loss: 0.0358, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.3075 Val BA-Score:  0.965632 Training Time:  18.856318 Inference Time:  0.583320
Epoch 30: BCE Loss: 0.0963
KAN Loss: 0.0301, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2545 Val BA-Score:  0.963942 Training Time:  18.964830 Inference Time:  0.580647
Epoch 31: BCE Loss: 0.0966
KAN Loss: 0.0251, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2924 Val BA-Score:  0.963459 Training Time:  18.819678 Inference Time:  0.584733
Epoch 32: BCE Loss: 0.0945
KAN Loss: 0.0211, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2717 Val BA-Score:  0.963942 Training Time:  18.896111 Inference Time:  0.583135
Epoch 33: BCE Loss: 0.0975
KAN Loss: 0.0182, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2852 Val BA-Score:  0.964633 Training Time:  18.832143 Inference Time:  0.584492
Epoch 34: BCE Loss: 0.0936
KAN Loss: 0.0162, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2958 Val BA-Score:  0.964216 Training Time:  18.928209 Inference Time:  0.584750
Epoch 35: BCE Loss: 0.0945
KAN Loss: 0.0151, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2852 Val BA-Score:  0.963459 Training Time:  18.828860 Inference Time:  0.588583
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.9708601282314523 0.9784210466250282 0.9868013349891323 0.9708601282314523 0.9756751280667781
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     34537
           1       0.98      1.00      0.99      6756
           2       0.98      0.92      0.95      3467

    accuracy                           0.99     44760
   macro avg       0.99      0.97      0.98     44760
weighted avg       0.99      0.99      0.99     44760

Low Quality (Post 2020)
0.8683935112506541 0.8548648230284192 0.8421684895724203 0.8683935112506541 0.93722586303903
              precision    recall  f1-score   support

           0       1.00      0.99      0.99      1960
           1       0.96      1.00      0.98       235
           2       0.57      0.62      0.59        26

    accuracy                           0.99      2221
   macro avg       0.84      0.87      0.85      2221
weighted avg       0.99      0.99      0.99      2221


High Quality Post 2020
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.978465  0.001367  0.000483      8
                     mean       std       sem  count
Model                                               
Baseline_no_gMLP  0.97099  0.002484  0.000878      8
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.975643  0.001634  0.000578      8

Low Quality Post 2020
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.845645  0.039363  0.013917      8
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.885796  0.021521  0.007609      8
                      mean      std       sem  count
Model                                               
Baseline_no_gMLP  0.923515  0.03918  0.013852      8
*************************Fold:  8 **********************************

Using: cuda:0!
Total Trainable Parameters:  1033761.0
Total Parameters:  1033761.0
Epoch 1: BCE Loss: 1.0642
KAN Loss: 0.0773, MH-SMoE (SA) Loss: 0.1202
Val Loss: 1.0120 Val BA-Score:  0.601370 Training Time:  18.809482 Inference Time:  0.586704
Epoch 2: BCE Loss: 0.5409
KAN Loss: 0.0539, MH-SMoE (SA) Loss: 0.0510
Val Loss: 0.4971 Val BA-Score:  0.901376 Training Time:  18.798605 Inference Time:  0.585544
Epoch 3: BCE Loss: 0.3216
KAN Loss: 0.0538, MH-SMoE (SA) Loss: 0.0416
Val Loss: 0.3989 Val BA-Score:  0.948858 Training Time:  18.903514 Inference Time:  0.582365
Epoch 4: BCE Loss: 0.2507
KAN Loss: 0.0584, MH-SMoE (SA) Loss: 0.0392
Val Loss: 0.4264 Val BA-Score:  0.954684 Training Time:  18.891742 Inference Time:  0.584926
Epoch 5: BCE Loss: 0.2028
KAN Loss: 0.0659, MH-SMoE (SA) Loss: 0.0371
Val Loss: 0.3901 Val BA-Score:  0.942235 Training Time:  19.021089 Inference Time:  0.586480
Epoch 6: BCE Loss: 0.1809
KAN Loss: 0.0738, MH-SMoE (SA) Loss: 0.0350
Val Loss: 0.4811 Val BA-Score:  0.831829 Training Time:  19.395721 Inference Time:  0.581725
Epoch 7: BCE Loss: 0.1698
KAN Loss: 0.0824, MH-SMoE (SA) Loss: 0.0344
Val Loss: 0.2975 Val BA-Score:  0.941362 Training Time:  18.854390 Inference Time:  0.582166
Epoch 8: BCE Loss: 0.1608
KAN Loss: 0.0901, MH-SMoE (SA) Loss: 0.0336
Val Loss: 0.2089 Val BA-Score:  0.959183 Training Time:  18.997548 Inference Time:  0.583902
Epoch 9: BCE Loss: 0.1560
KAN Loss: 0.0969, MH-SMoE (SA) Loss: 0.0333
Val Loss: 0.2423 Val BA-Score:  0.952644 Training Time:  20.158360 Inference Time:  0.583227
Epoch 10: BCE Loss: 0.1552
KAN Loss: 0.1016, MH-SMoE (SA) Loss: 0.0327
Val Loss: 0.2046 Val BA-Score:  0.965906 Training Time:  18.957218 Inference Time:  0.583469
Epoch 11: BCE Loss: 0.1434
KAN Loss: 0.1041, MH-SMoE (SA) Loss: 0.0323
Val Loss: 0.2346 Val BA-Score:  0.953619 Training Time:  18.870464 Inference Time:  0.583385
Epoch 12: BCE Loss: 0.1404
KAN Loss: 0.1045, MH-SMoE (SA) Loss: 0.0324
Val Loss: 0.1987 Val BA-Score:  0.966772 Training Time:  18.957191 Inference Time:  0.586670
Epoch 13: BCE Loss: 0.1400
KAN Loss: 0.1033, MH-SMoE (SA) Loss: 0.0317
Val Loss: 0.3646 Val BA-Score:  0.878493 Training Time:  18.829803 Inference Time:  0.584898
Epoch 14: BCE Loss: 0.1415
KAN Loss: 0.1016, MH-SMoE (SA) Loss: 0.0317
Val Loss: 0.3662 Val BA-Score:  0.955436 Training Time:  19.024528 Inference Time:  0.581479
Epoch 15: BCE Loss: 0.1326
KAN Loss: 0.0995, MH-SMoE (SA) Loss: 0.0318
Val Loss: 0.2119 Val BA-Score:  0.966432 Training Time:  18.889111 Inference Time:  0.584595
Epoch 16: BCE Loss: 0.1274
KAN Loss: 0.0971, MH-SMoE (SA) Loss: 0.0315
Val Loss: 0.2287 Val BA-Score:  0.967959 Training Time:  19.148637 Inference Time:  0.585369
Epoch 17: BCE Loss: 0.1235
KAN Loss: 0.0944, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.2219 Val BA-Score:  0.967880 Training Time:  18.856014 Inference Time:  0.586335
Epoch 18: BCE Loss: 0.1188
KAN Loss: 0.0910, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.2247 Val BA-Score:  0.962522 Training Time:  19.111631 Inference Time:  0.581441
Epoch 19: BCE Loss: 0.1187
KAN Loss: 0.0879, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.2433 Val BA-Score:  0.964709 Training Time:  18.971510 Inference Time:  0.589114
Epoch 20: BCE Loss: 0.1157
KAN Loss: 0.0835, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.2762 Val BA-Score:  0.963810 Training Time:  18.956732 Inference Time:  0.583817
Epoch 21: BCE Loss: 0.1165
KAN Loss: 0.0787, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2108 Val BA-Score:  0.965916 Training Time:  19.087233 Inference Time:  0.585832
Epoch 22: BCE Loss: 0.1118
KAN Loss: 0.0742, MH-SMoE (SA) Loss: 0.0309
Val Loss: 0.2494 Val BA-Score:  0.969054 Training Time:  18.899845 Inference Time:  0.584546
Epoch 23: BCE Loss: 0.1098
KAN Loss: 0.0683, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2845 Val BA-Score:  0.968310 Training Time:  18.989505 Inference Time:  0.585936
Epoch 24: BCE Loss: 0.1094
KAN Loss: 0.0628, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.3181 Val BA-Score:  0.967397 Training Time:  18.888834 Inference Time:  0.588408
Epoch 25: BCE Loss: 0.1059
KAN Loss: 0.0575, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2834 Val BA-Score:  0.967364 Training Time:  18.989247 Inference Time:  0.580798
Epoch 26: BCE Loss: 0.1023
KAN Loss: 0.0512, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2589 Val BA-Score:  0.969295 Training Time:  19.041530 Inference Time:  0.585595
Epoch 27: BCE Loss: 0.1027
KAN Loss: 0.0461, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2591 Val BA-Score:  0.967397 Training Time:  18.932722 Inference Time:  0.584128
Epoch 28: BCE Loss: 0.1003
KAN Loss: 0.0408, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2709 Val BA-Score:  0.969262 Training Time:  18.854578 Inference Time:  0.586237
Epoch 29: BCE Loss: 0.0985
KAN Loss: 0.0359, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2683 Val BA-Score:  0.969953 Training Time:  18.968994 Inference Time:  0.586295
Epoch 30: BCE Loss: 0.0988
KAN Loss: 0.0305, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2814 Val BA-Score:  0.971534 Training Time:  18.917534 Inference Time:  0.584105
Epoch 31: BCE Loss: 0.0974
KAN Loss: 0.0257, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.3103 Val BA-Score:  0.963142 Training Time:  19.102806 Inference Time:  0.576814
Epoch 32: BCE Loss: 0.0951
KAN Loss: 0.0220, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.3053 Val BA-Score:  0.967814 Training Time:  19.189960 Inference Time:  0.589026
Epoch 33: BCE Loss: 0.0952
KAN Loss: 0.0192, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2767 Val BA-Score:  0.970052 Training Time:  19.000519 Inference Time:  0.584901
Epoch 34: BCE Loss: 0.0968
KAN Loss: 0.0173, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2792 Val BA-Score:  0.969262 Training Time:  18.863713 Inference Time:  0.584090
Epoch 35: BCE Loss: 0.0967
KAN Loss: 0.0163, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2790 Val BA-Score:  0.968055 Training Time:  19.013534 Inference Time:  0.582899
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.9719177188477394 0.9790483500728503 0.9869256174016504 0.9719177188477394 0.9763360230144648
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     34537
           1       0.98      1.00      0.99      6756
           2       0.98      0.92      0.95      3467

    accuracy                           0.99     44760
   macro avg       0.99      0.97      0.98     44760
weighted avg       0.99      0.99      0.99     44760

Low Quality (Post 2020)
0.8813840920983779 0.8642465515614753 0.848576073830658 0.8813840920983779 0.9414409600523779
              precision    recall  f1-score   support

           0       1.00      0.99      0.99      1960
           1       0.96      1.00      0.98       235
           2       0.59      0.65      0.62        26

    accuracy                           0.99      2221
   macro avg       0.85      0.88      0.86      2221
weighted avg       0.99      0.99      0.99      2221


High Quality Post 2020
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.978529  0.001294  0.000431      9
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.971093  0.002344  0.000781      9
                     mean       std       sem  count
Model                                               
Baseline_no_gMLP  0.97572  0.001546  0.000515      9

Low Quality Post 2020
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.847712  0.037339  0.012446      9
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.885306  0.020185  0.006728      9
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.925507  0.037133  0.012378      9
*************************Fold:  9 **********************************

Using: cuda:0!
Total Trainable Parameters:  1033761.0
Total Parameters:  1033761.0
Epoch 1: BCE Loss: 1.0278
KAN Loss: 0.0776, MH-SMoE (SA) Loss: 0.1202
Val Loss: 0.9080 Val BA-Score:  0.768717 Training Time:  19.077990 Inference Time:  0.580205
Epoch 2: BCE Loss: 0.4987
KAN Loss: 0.0545, MH-SMoE (SA) Loss: 0.0489
Val Loss: 0.4904 Val BA-Score:  0.935580 Training Time:  18.992358 Inference Time:  0.587242
Epoch 3: BCE Loss: 0.3137
KAN Loss: 0.0529, MH-SMoE (SA) Loss: 0.0413
Val Loss: 0.4231 Val BA-Score:  0.904979 Training Time:  18.939326 Inference Time:  0.585247
Epoch 4: BCE Loss: 0.2469
KAN Loss: 0.0569, MH-SMoE (SA) Loss: 0.0377
Val Loss: 0.5044 Val BA-Score:  0.834176 Training Time:  18.851105 Inference Time:  0.584928
Epoch 5: BCE Loss: 0.2104
KAN Loss: 0.0640, MH-SMoE (SA) Loss: 0.0360
Val Loss: 0.2743 Val BA-Score:  0.945142 Training Time:  19.001343 Inference Time:  0.583713
Epoch 6: BCE Loss: 0.1775
KAN Loss: 0.0731, MH-SMoE (SA) Loss: 0.0349
Val Loss: 0.2162 Val BA-Score:  0.959303 Training Time:  19.039453 Inference Time:  0.588361
Epoch 7: BCE Loss: 0.1683
KAN Loss: 0.0825, MH-SMoE (SA) Loss: 0.0343
Val Loss: 0.4707 Val BA-Score:  0.695950 Training Time:  19.138359 Inference Time:  0.584670
Epoch 8: BCE Loss: 0.1645
KAN Loss: 0.0895, MH-SMoE (SA) Loss: 0.0338
Val Loss: 0.1882 Val BA-Score:  0.960969 Training Time:  18.905104 Inference Time:  0.593834
Epoch 9: BCE Loss: 0.1605
KAN Loss: 0.0959, MH-SMoE (SA) Loss: 0.0329
Val Loss: 0.4971 Val BA-Score:  0.790732 Training Time:  19.073976 Inference Time:  0.584722
Epoch 10: BCE Loss: 0.1546
KAN Loss: 0.1006, MH-SMoE (SA) Loss: 0.0324
Val Loss: 0.1845 Val BA-Score:  0.966269 Training Time:  18.870678 Inference Time:  0.583620
Epoch 11: BCE Loss: 0.1462
KAN Loss: 0.1027, MH-SMoE (SA) Loss: 0.0322
Val Loss: 0.2153 Val BA-Score:  0.939654 Training Time:  18.985734 Inference Time:  0.585259
Epoch 12: BCE Loss: 0.1442
KAN Loss: 0.1032, MH-SMoE (SA) Loss: 0.0321
Val Loss: 0.4935 Val BA-Score:  0.747805 Training Time:  19.039753 Inference Time:  0.581927
Epoch 13: BCE Loss: 0.1416
KAN Loss: 0.1025, MH-SMoE (SA) Loss: 0.0317
Val Loss: 0.5341 Val BA-Score:  0.689921 Training Time:  19.086877 Inference Time:  0.575835
Epoch 14: BCE Loss: 0.1337
KAN Loss: 0.1016, MH-SMoE (SA) Loss: 0.0317
Val Loss: 0.2452 Val BA-Score:  0.954462 Training Time:  18.871252 Inference Time:  0.583581
Epoch 15: BCE Loss: 0.1290
KAN Loss: 0.0996, MH-SMoE (SA) Loss: 0.0316
Val Loss: 0.1831 Val BA-Score:  0.967497 Training Time:  19.037588 Inference Time:  0.581830
Epoch 16: BCE Loss: 0.1284
KAN Loss: 0.0973, MH-SMoE (SA) Loss: 0.0313
Val Loss: 0.2397 Val BA-Score:  0.967476 Training Time:  19.086287 Inference Time:  0.579105
Epoch 17: BCE Loss: 0.1230
KAN Loss: 0.0946, MH-SMoE (SA) Loss: 0.0315
Val Loss: 0.2325 Val BA-Score:  0.966180 Training Time:  19.271051 Inference Time:  0.578330
Epoch 18: BCE Loss: 0.1243
KAN Loss: 0.0910, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.3859 Val BA-Score:  0.949433 Training Time:  18.945925 Inference Time:  0.583351
Epoch 19: BCE Loss: 0.1213
KAN Loss: 0.0879, MH-SMoE (SA) Loss: 0.0312
Val Loss: 0.2373 Val BA-Score:  0.961221 Training Time:  19.152762 Inference Time:  0.576620
Epoch 20: BCE Loss: 0.1168
KAN Loss: 0.0832, MH-SMoE (SA) Loss: 0.0311
Val Loss: 0.2089 Val BA-Score:  0.962265 Training Time:  19.110026 Inference Time:  0.581763
Epoch 21: BCE Loss: 0.1131
KAN Loss: 0.0788, MH-SMoE (SA) Loss: 0.0309
Val Loss: 0.3159 Val BA-Score:  0.959930 Training Time:  19.314402 Inference Time:  0.589646
Epoch 22: BCE Loss: 0.1098
KAN Loss: 0.0740, MH-SMoE (SA) Loss: 0.0310
Val Loss: 0.2623 Val BA-Score:  0.966996 Training Time:  18.992667 Inference Time:  0.584659
Epoch 23: BCE Loss: 0.1113
KAN Loss: 0.0689, MH-SMoE (SA) Loss: 0.0308
Val Loss: 0.2323 Val BA-Score:  0.964613 Training Time:  18.937164 Inference Time:  0.583992
Epoch 24: BCE Loss: 0.1077
KAN Loss: 0.0639, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.2425 Val BA-Score:  0.965149 Training Time:  19.125526 Inference Time:  0.585122
Epoch 25: BCE Loss: 0.1063
KAN Loss: 0.0575, MH-SMoE (SA) Loss: 0.0307
Val Loss: 0.2178 Val BA-Score:  0.965873 Training Time:  19.175376 Inference Time:  0.586799
Epoch 26: BCE Loss: 0.1033
KAN Loss: 0.0521, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2474 Val BA-Score:  0.968287 Training Time:  19.080922 Inference Time:  0.591047
Epoch 27: BCE Loss: 0.1010
KAN Loss: 0.0465, MH-SMoE (SA) Loss: 0.0306
Val Loss: 0.2309 Val BA-Score:  0.963813 Training Time:  18.950925 Inference Time:  0.583282
Epoch 28: BCE Loss: 0.0981
KAN Loss: 0.0415, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2406 Val BA-Score:  0.967771 Training Time:  19.020617 Inference Time:  0.586066
Epoch 29: BCE Loss: 0.0991
KAN Loss: 0.0357, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2517 Val BA-Score:  0.966663 Training Time:  18.954791 Inference Time:  0.586355
Epoch 30: BCE Loss: 0.0968
KAN Loss: 0.0303, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2301 Val BA-Score:  0.966544 Training Time:  19.025867 Inference Time:  0.582996
Epoch 31: BCE Loss: 0.0966
KAN Loss: 0.0254, MH-SMoE (SA) Loss: 0.0305
Val Loss: 0.2164 Val BA-Score:  0.963297 Training Time:  18.882049 Inference Time:  0.586696
Epoch 32: BCE Loss: 0.0960
KAN Loss: 0.0217, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2214 Val BA-Score:  0.966412 Training Time:  18.956707 Inference Time:  0.584858
Epoch 33: BCE Loss: 0.0947
KAN Loss: 0.0188, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2153 Val BA-Score:  0.968320 Training Time:  18.921290 Inference Time:  0.596626
Epoch 34: BCE Loss: 0.0957
KAN Loss: 0.0169, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2422 Val BA-Score:  0.968769 Training Time:  19.050469 Inference Time:  0.584841
Epoch 35: BCE Loss: 0.0953
KAN Loss: 0.0159, MH-SMoE (SA) Loss: 0.0304
Val Loss: 0.2235 Val BA-Score:  0.968594 Training Time:  18.843979 Inference Time:  0.585921
Baseline_no_gMLP Result:
High Quality (Post 2020)
0.9754364631629987 0.9809365681275443 0.9869437787651388 0.9754364631629987 0.9783212520277015
              precision    recall  f1-score   support

           0       0.99      1.00      1.00     34537
           1       0.98      1.00      0.99      6756
           2       0.98      0.93      0.96      3467

    accuracy                           0.99     44760
   macro avg       0.99      0.98      0.98     44760
weighted avg       0.99      0.99      0.99     44760

Low Quality (Post 2020)
0.9012428048142334 0.7937759125814181 0.7507806381392311 0.9012428048142334 0.8860504694499894
              precision    recall  f1-score   support

           0       1.00      0.97      0.99      1960
           1       0.97      1.00      0.98       235
           2       0.29      0.73      0.41        26

    accuracy                           0.97      2221
   macro avg       0.75      0.90      0.79      2221
weighted avg       0.99      0.97      0.98      2221


High Quality Post 2020
                     mean       std       sem  count
Model                                               
Baseline_no_gMLP  0.97877  0.001438  0.000455     10
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.971528  0.002602  0.000823     10
                     mean       std       sem  count
Model                                               
Baseline_no_gMLP  0.97598  0.001674  0.000529     10

Low Quality Post 2020
                      mean       std      sem  count
Model                                               
Baseline_no_gMLP  0.842318  0.039118  0.01237     10
                    mean       std       sem  count
Model                                              
Baseline_no_gMLP  0.8869  0.019687  0.006225     10
                      mean       std       sem  count
Model                                                
Baseline_no_gMLP  0.921561  0.037167  0.011753     10
